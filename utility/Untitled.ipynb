{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "4c9a41b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "\n",
    "###TO DO MAKE THE CODE MORE MODULAR AND REMOVE THE SHITTY MAGIC VARIABLE\n",
    "### I WILL NOT REFACTOR THIS UNTIL THE MAIN FEATURE IS DONE\n",
    "\n",
    "def convert_snapshot(data, desired_key = None):\n",
    "    \"\"\"\n",
    "    this extract desired keys from list of dicts from snapshot\n",
    "    \"\"\"\n",
    "    data_dictionary = map(lambda x: x.to_dict(), data)\n",
    "    if (desired_key is not None):\n",
    "        data_dictionary = map(lambda x: dict((k, x[k]) for k in desired_key if k in x), list(data_dictionary))\n",
    "\n",
    "    return list(data_dictionary)\n",
    "\n",
    "\n",
    "def fill_non_existent_column(df, is_caregiver=False):\n",
    "    \"\"\"\n",
    "    This fill the df with unique problems column i\n",
    "    \"\"\"\n",
    "    if is_caregiver is False:\n",
    "        new_column = ['ADHD-Hiperaktif-dan-kurang-fokus', 'Depresi', 'Gangguan-kecemasan', 'Gangguan-makan',\n",
    "                      'Gangguan-stres-pascatrauma', 'Skizofrenia']\n",
    "    else:\n",
    "        new_column = ['Caregiver-ADHD-Hiperaktif-dan-kurang-fokus', 'Caregiver-Depresi', 'Caregiver-Gangguan-kecemasan',\n",
    "                      'Caregiver-Gangguan-makan', 'Caregiver-Gangguan-stres-pascatrauma', 'Caregiver-Skizofrenia']\n",
    "\n",
    "    for col in new_column:\n",
    "        if (col in df.columns):\n",
    "            pass\n",
    "        else:\n",
    "            df[col] = 0\n",
    "\n",
    "\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32, text_processed=False):\n",
    "    \"\"\"\n",
    "    A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "    \"\"\"\n",
    "    dataframe = dataframe.copy()\n",
    "    if(text_processed):\n",
    "        processed_text = dataframe.pop('text_processed')\n",
    "        ds = tf.data.Dataset.from_tensor_slices(dict(dataframe))\n",
    "        ds_processed = tf.data.Dataset.from_tensors(dict(processed_text))\n",
    "        ds = tf.data.Dataset.zip((ds,ds_processed))\n",
    "    else:\n",
    "        ds = tf.data.Dataset.from_tensor_slices(dict(dataframe))\n",
    "\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds\n",
    "\n",
    "\n",
    "\n",
    "def age(birthdate):\n",
    "    today = date.today()\n",
    "    age = today.year - birthdate.year - ((today.month, today.day) < (birthdate.month, birthdate.day))\n",
    "    return age\n",
    "\n",
    "def convert_categorical_data(df, col, is_caregiver = False):\n",
    "    \"\"\"\n",
    "    Convert categorical data that splited by space to their own column in pandas dataframe , making them like one hot encoded\n",
    "    \"\"\"\n",
    "    ### Join every string in every row, split the result, pull out the unique values.\n",
    "    genres = np.unique(' '.join(df[col]).split(' '))\n",
    "    ### Drop 'NA'\n",
    "    genres = np.delete(genres, np.where(genres == ''))\n",
    "    if(not is_caregiver):\n",
    "        for genre in genres:\n",
    "            df[genre] = df[col].str.contains(genre).astype('int')\n",
    "    else:\n",
    "        for genre in genres:\n",
    "            df['Caregiver-'+genre] = df[col].str.contains(genre).astype('int')\n",
    "    df.drop(col, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "def change_column_name(df, old_name, new_name):\n",
    "    \"\"\"\n",
    "    replace list of column name in old_name to new colum name in new_name\n",
    "    the order of old_name and new_name need to be exact\n",
    "    \"\"\"\n",
    "    res = {old_name[i]: new_name[i] for i in range(len(new_name))}\n",
    "    df.rename(columns=res, inplace=True)\n",
    "\n",
    "\n",
    "def Merge(dict1, dict2):\n",
    "    \"\"\"\n",
    "    Python code to merge dict\n",
    "    \"\"\"\n",
    "    res = {**dict1, **dict2}\n",
    "    return res\n",
    "\n",
    "\n",
    "def unpack_caregiver_snapshot(data):\n",
    "    \"\"\"\n",
    "\n",
    "    :param data: data is a snapshot of chatroom collection\n",
    "    :return: list of caregiver in form of dictionary\n",
    "    \"\"\"\n",
    "    desired_keys = [\"problems\", \"birthday\", \"gender\", \"caregiver_id\", \"text\"]\n",
    "    # this unpack the value of snapshot list and turn the snapshot into dictionary also add aditional key for caregiver_id\n",
    "    caregiver_dict_unpacked = map(lambda feature: Merge(feature.to_dict(), {'caregiver_id': feature.id}), data)\n",
    "\n",
    "    # this unpack the snapshot in 'caregiver' snapshot and add them back to main dictionary\n",
    "    caregiver_dict = map(lambda feature: Merge(feature, feature.pop('caregiver').get().to_dict()),\n",
    "                         caregiver_dict_unpacked)\n",
    "\n",
    "    #check for room capacity\n",
    "    caregiver_dict = filter(lambda feature: feature['max_user'] > len(feature['users']) , caregiver_dict)\n",
    "\n",
    "    # this seperate desired keys from unused keys\n",
    "    caregiver_dict = map(lambda x: dict((k, x[k]) for k in desired_keys if k in x), caregiver_dict)\n",
    "\n",
    "    # this convert birthday stamp into interger age\n",
    "    caregiver_dict = map(lambda feature: Merge(feature, {'age': age(feature.pop('birthday'))}), caregiver_dict)\n",
    "\n",
    "    return list(caregiver_dict)\n",
    "\n",
    "def convert_caregiver_dictList_to_df(dictionary):\n",
    "    \"\"\"\n",
    "    :param dictionary: list of dictionary\n",
    "    :return: dataframe of the said dictionary\n",
    "    \"\"\"\n",
    "    # Creates DataFrame.\n",
    "    df = pd.DataFrame(dictionary)\n",
    "    #change column name to feature according to the model\n",
    "    change_column_name(df, ['problems','gender','caregiver_id','age'],['Caregiver_Tipe_Masalah','Caregiver_Gender','CAREGIVER_ID','Caregiver_Age'])\n",
    "    #convert categorical data into their own column\n",
    "    convert_categorical_data(df, \"Caregiver_Tipe_Masalah\", is_caregiver = True)\n",
    "    #fill missing column with default value\n",
    "    fill_non_existent_column(df, is_caregiver = True)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc45c81b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3e0468d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from firebase_admin import credentials, firestore, initialize_app\n",
    "cred = credentials.Certificate(\"key.json\")\n",
    "default_app = initialize_app(cred)\n",
    "db = firestore.client()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "445355e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MAIN_TEXT_MODEL = tf.keras.models.load_model('saved_manual_model/text_query_v1')\n",
    "MAIN_USER_MODEL = tf.keras.models.load_model('saved_manual_model/user_query_v1')\n",
    "MAIN_CAREGIVER_MODEL = tf.keras.models.load_model('saved_manual_model/caregiver_query_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c254f6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "db_ref = db.collection('chat_room_pref')\n",
    "data = db_ref.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c57d73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ddc738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f925edfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_recommenders as tfrs\n",
    "data = unpack_caregiver_snapshot(data)\n",
    "data = convert_caregiver_dictList_to_df(data)\n",
    "caregiver_ds = df_to_dataset(data)\n",
    "TEXT_INDEX = tfrs.layers.factorized_top_k.BruteForce(MAIN_TEXT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "b5996f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_INDEX = tfrs.layers.factorized_top_k.BruteForce(MAIN_TEXT_MODEL)\n",
    "\n",
    "\n",
    "\n",
    "INDEX = tfrs.layers.factorized_top_k.BruteForce(MAIN_USER_MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "28da969d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'Caregiver_Gender': <tf.Tensor 'args_12:0' shape=(None,) dtype=string>, 'CAREGIVER_ID': <tf.Tensor 'args_0:0' shape=(None,) dtype=string>, 'text': <tf.Tensor 'args_13:0' shape=(None,) dtype=string>, 'Caregiver_Age': <tf.Tensor 'args_11:0' shape=(None,) dtype=int64>, 'Caregiver-Anxiety': <tf.Tensor 'args_2:0' shape=(None,) dtype=int32>, 'Caregiver-Depresi': <tf.Tensor 'args_3:0' shape=(None,) dtype=int32>, 'Caregiver-Gangguan-kecemasan': <tf.Tensor 'args_4:0' shape=(None,) dtype=int32>, 'Caregiver-Gangguan-stress-pascatrauma': <tf.Tensor 'args_7:0' shape=(None,) dtype=int32>, 'Caregiver-Kekerasan': <tf.Tensor 'args_8:0' shape=(None,) dtype=int32>, 'Caregiver-Masalah-Tidur': <tf.Tensor 'args_9:0' shape=(None,) dtype=int32>, 'Caregiver-Skizofrenia': <tf.Tensor 'args_10:0' shape=(None,) dtype=int32>, 'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus': <tf.Tensor 'args_1:0' shape=(None,) dtype=int64>, 'Caregiver-Gangguan-makan': <tf.Tensor 'args_5:0' shape=(None,) dtype=int64>, 'Caregiver-Gangguan-stres-pascatrauma': <tf.Tensor 'args_6:0' shape=(None,) dtype=int64>}. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.layers.factorized_top_k.BruteForce at 0x1a127d37fa0>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update this\n",
    "TEXT_INDEX.index_from_dataset(\n",
    "    caregiver_ds.map(lambda features: (features['CAREGIVER_ID'], MAIN_TEXT_MODEL([features['text']])))\n",
    ")\n",
    "\n",
    "# update_this\n",
    "INDEX.index_from_dataset(\n",
    "    caregiver_ds.map(lambda features: (features['CAREGIVER_ID'], MAIN_CAREGIVER_MODEL(features)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1bed72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "348cfdcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Gender': ['Pria'], 'Age': [30], 'ADHD-Hiperaktif-dan-kurang-fokus': [0], 'Depresi': [1], 'Gangguan-kecemasan': [0], 'Gangguan-makan': [0], 'Gangguan-stres-pascatrauma': [1], 'Skizofrenia': [0]}\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'Gender': ['Pria'], 'Age': [<tf.Tensor: shape=(), dtype=int32, numpy=30>], 'ADHD-Hiperaktif-dan-kurang-fokus': [<tf.Tensor: shape=(), dtype=int32, numpy=0>], 'Depresi': [<tf.Tensor: shape=(), dtype=int32, numpy=1>], 'Gangguan-kecemasan': [<tf.Tensor: shape=(), dtype=int32, numpy=0>], 'Gangguan-makan': [<tf.Tensor: shape=(), dtype=int32, numpy=0>], 'Gangguan-stres-pascatrauma': [<tf.Tensor: shape=(), dtype=int32, numpy=1>], 'Skizofrenia': [<tf.Tensor: shape=(), dtype=int32, numpy=0>]}. Consider rewriting this model with the Functional API.\n",
      "Top recommendations: [b'db5wFkLGR4pb7ongAd3e']\n",
      "Top recommendations: [b' HUDwzgELY1OEzwieoHXK']\n",
      "tf.Tensor(\n",
      "[[ 2.7937052e-01 -2.5666751e-02 -1.3149159e-01 -2.1588609e-01\n",
      "  -2.2960218e-02 -2.2883387e-01 -1.7346169e-01 -6.4872846e-02\n",
      "  -2.3486321e-01  7.8157082e-02  2.2771671e-01 -1.0847397e-01\n",
      "  -1.9453070e-01  3.1591713e-01  1.4165582e-01  5.6409419e-02\n",
      "   5.1611908e-02  1.4780410e-01  6.2259149e-02  1.6942768e-01\n",
      "   1.1273560e-01 -1.2807637e-01 -4.7652092e-02  2.5380790e-01\n",
      "  -1.8733555e-01  1.1730904e-02  1.0061440e-01 -1.2786148e-01\n",
      "   4.1663740e-03  1.2821472e-01  3.8503781e-01  2.0027758e-01\n",
      "   1.9084729e-01  7.0396133e-02  9.0815881e-03 -3.2037225e-02\n",
      "   9.8407986e-03 -8.8083446e-02  1.2190298e-01  4.2459708e-02\n",
      "  -1.4164943e-01 -4.7461402e-02 -1.7951630e-01 -1.8083632e-05\n",
      "  -1.3089561e-01  5.3548150e-02  1.6794558e-01 -2.0936133e-01\n",
      "   5.4691862e-02  4.4488646e-02]], shape=(1, 50), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = ['Gender', 'Age', 'ADHD-Hiperaktif-dan-kurang-fokus', 'Depresi', 'Gangguan-kecemasan', 'Gangguan-makan',\n",
    "         'Gangguan-stres-pascatrauma', 'Skizofrenia']\n",
    "value = ['Pria', 30, 0, 1, 0, 0, 1, 0]\n",
    "dictionary_Test = dict((el, ([value[ix]])) for ix, el in enumerate(a))\n",
    "print(dictionary_Test)\n",
    "\n",
    "a, titles = INDEX(dictionary_Test, k=1)\n",
    "print(f\"Top recommendations: {titles[0]}\")\n",
    "\n",
    "a, titles = TEXT_INDEX(np.array([\"AAAA sa sayang\"]), k=1)\n",
    "\n",
    "print(f\"Top recommendations: {titles[0]}\")\n",
    "\n",
    "print(MAIN_TEXT_MODEL(np.array([\"aa sss\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "725097f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_user_snapshot(data):\n",
    "    print(type(data))\n",
    "    if (type(data) != list):\n",
    "        data = [data]\n",
    "    print(type(data))\n",
    "    data = convert_snapshot(data, desired_key=[\"problems\", \"gender\", \"birthday\", \"text\"])\n",
    "    data = map(lambda feature: Merge(feature, {'age': age(feature.pop('birthday'))}), data)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def convert_user_dictList_to_df(dictionary):\n",
    "    \"\"\"\n",
    "    :param dictionary: list of dictionary\n",
    "    :return: dataframe of the said dictionary\n",
    "    \"\"\"\n",
    "    # Creates DataFrame.\n",
    "    df = pd.DataFrame(dictionary)\n",
    "    #change column name to feature according to the model\n",
    "    change_column_name(df, ['problems','gender','caregiver_id','age'],['Tipe_Masalah','Gender','CAREGIVER_ID','Age'])\n",
    "    #convert categorical data into their own column\n",
    "    convert_categorical_data(df, \"Tipe_Masalah\", is_caregiver = False)\n",
    "    #fill missing column with default value\n",
    "    fill_non_existent_column(df, is_caregiver = False)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "fa08843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_user = db.collection('users').document(\"4R3TTPINWhPzUvwIUEXbldtNAY72\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "3358e781",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ref = db_user.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "fbdad883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rating': [4, 5], 'gender': 'Pria', 'point': 0, 'text': 'aku stress', 'img': 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/60/John_Cena_July_2018.jpg/640px-John_Cena_July_2018.jpg', 'name': 'Dhiva', 'problems': ' Anxiety Kekerasan Masalah-Tidur', 'birthday': DatetimeWithNanoseconds(2000, 11, 16, 16, 0, tzinfo=datetime.timezone.utc)}\n"
     ]
    }
   ],
   "source": [
    "data = data_ref\n",
    "print(data.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "f0ae0f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'google.cloud.firestore_v1.base_document.DocumentSnapshot'>\n",
      "<class 'list'>\n",
      "[{'problems': ' Anxiety Kekerasan Masalah-Tidur', 'gender': 'Pria', 'text': 'aku stress', 'age': 21}]\n"
     ]
    }
   ],
   "source": [
    "data = list(unpack_user_snapshot(data))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "966d1c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>text</th>\n",
       "      <th>Age</th>\n",
       "      <th>Anxiety</th>\n",
       "      <th>Kekerasan</th>\n",
       "      <th>Masalah-Tidur</th>\n",
       "      <th>ADHD-Hiperaktif-dan-kurang-fokus</th>\n",
       "      <th>Depresi</th>\n",
       "      <th>Gangguan-kecemasan</th>\n",
       "      <th>Gangguan-makan</th>\n",
       "      <th>Gangguan-stres-pascatrauma</th>\n",
       "      <th>Skizofrenia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pria</td>\n",
       "      <td>aku stress</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gender        text  Age  Anxiety  Kekerasan  Masalah-Tidur  \\\n",
       "0   Pria  aku stress   21        1          1              1   \n",
       "\n",
       "   ADHD-Hiperaktif-dan-kurang-fokus  Depresi  Gangguan-kecemasan  \\\n",
       "0                                 0        0                   0   \n",
       "\n",
       "   Gangguan-makan  Gangguan-stres-pascatrauma  Skizofrenia  \n",
       "0               0                           0            0  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = convert_user_dictList_to_df(data)\n",
    "data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e3d55e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =data.to_dict('records')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b068ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "cdb3e170",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in data.items():\n",
    "    data[k] = [v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "5b847c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'Gender': ['Pria'], 'text': ['aku stress'], 'Age': [<tf.Tensor: shape=(), dtype=int32, numpy=21>], 'Anxiety': [<tf.Tensor: shape=(), dtype=int32, numpy=1>], 'Kekerasan': [<tf.Tensor: shape=(), dtype=int32, numpy=1>], 'Masalah-Tidur': [<tf.Tensor: shape=(), dtype=int32, numpy=1>], 'ADHD-Hiperaktif-dan-kurang-fokus': [<tf.Tensor: shape=(), dtype=int32, numpy=0>], 'Depresi': [<tf.Tensor: shape=(), dtype=int32, numpy=0>], 'Gangguan-kecemasan': [<tf.Tensor: shape=(), dtype=int32, numpy=0>], 'Gangguan-makan': [<tf.Tensor: shape=(), dtype=int32, numpy=0>], 'Gangguan-stres-pascatrauma': [<tf.Tensor: shape=(), dtype=int32, numpy=0>], 'Skizofrenia': [<tf.Tensor: shape=(), dtype=int32, numpy=0>]}. Consider rewriting this model with the Functional API.\n",
      "Top recommendations: [b'49cugkYNFakCCkId9Iai']\n"
     ]
    }
   ],
   "source": [
    "a, titles = INDEX(data, k=1)\n",
    "print(f\"Top recommendations: {titles[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "10bb635f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d81e2c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {\n",
    "    'recommendation': titles[0].numpy().tolist()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "7ef48a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test['recommendation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "a9c3c619",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = list(map(lambda string: string.decode(\"utf-8\"), test['recommendation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "24fc984c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['49cugkYNFakCCkId9Iai']"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "e5582c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_chat_room_pref = db.collection('chat_room_pref')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "d5f4adaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_data = db_chat_room_pref.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "06d35336",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = unpack_caregiver_snapshot(chat_data)\n",
    "data = convert_caregiver_dictList_to_df(data)\n",
    "caregiver_ds = df_to_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "df5f65c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec={'Caregiver_Gender': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'CAREGIVER_ID': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'text': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'Caregiver_Age': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'Caregiver-Anxiety': TensorSpec(shape=(None,), dtype=tf.int32, name=None), 'Caregiver-Depresi': TensorSpec(shape=(None,), dtype=tf.int32, name=None), 'Caregiver-Gangguan-kecemasan': TensorSpec(shape=(None,), dtype=tf.int32, name=None), 'Caregiver-Gangguan-stress-pascatrauma': TensorSpec(shape=(None,), dtype=tf.int32, name=None), 'Caregiver-Kekerasan': TensorSpec(shape=(None,), dtype=tf.int32, name=None), 'Caregiver-Masalah-Tidur': TensorSpec(shape=(None,), dtype=tf.int32, name=None), 'Caregiver-Skizofrenia': TensorSpec(shape=(None,), dtype=tf.int32, name=None), 'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'Caregiver-Gangguan-makan': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'Caregiver-Gangguan-stres-pascatrauma': TensorSpec(shape=(None,), dtype=tf.int64, name=None)}>"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caregiver_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "7b22592d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Caregiver_Gender': <tf.Tensor: shape=(4,), dtype=string, numpy=array([b'Perempuan', b'Pria', b'Perempuan', b'Pria'], dtype=object)>, 'CAREGIVER_ID': <tf.Tensor: shape=(4,), dtype=string, numpy=\n",
      "array([b'gSshnDOP0BbKXuaYTHZI', b'db5wFkLGR4pb7ongAd3e',\n",
      "       b'49cugkYNFakCCkId9Iai', b' HUDwzgELY1OEzwieoHXK'], dtype=object)>, 'text': <tf.Tensor: shape=(4,), dtype=string, numpy=\n",
      "array([b'Kesulitan dalam berkonsentrasi dan mengingat serta ucapan atau perilaku yang tidak teratur',\n",
      "       b'Kekerasan fisik', b'Lagi menunggu ujian sbmptn', b'aku stress'],\n",
      "      dtype=object)>, 'Caregiver_Age': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([21, 22, 21, 21], dtype=int64)>, 'Caregiver-Anxiety': <tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 0, 0, 1])>, 'Caregiver-Depresi': <tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 1, 0, 0])>, 'Caregiver-Gangguan-kecemasan': <tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 0, 1, 0])>, 'Caregiver-Gangguan-stress-pascatrauma': <tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 1, 0, 0])>, 'Caregiver-Kekerasan': <tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 0, 0, 1])>, 'Caregiver-Masalah-Tidur': <tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 0, 0, 1])>, 'Caregiver-Skizofrenia': <tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 0, 0, 0])>, 'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([0, 0, 0, 0], dtype=int64)>, 'Caregiver-Gangguan-makan': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([0, 0, 0, 0], dtype=int64)>, 'Caregiver-Gangguan-stres-pascatrauma': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([0, 0, 0, 0], dtype=int64)>}\n"
     ]
    }
   ],
   "source": [
    "for feature in caregiver_ds.take(5):\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "7873c4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asus\\anaconda3\\envs\\notebook\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "c789403d",
   "metadata": {},
   "outputs": [],
   "source": [
    "caregiver_processed = caregiver_ds.map(lambda features: (features['CAREGIVER_ID'], MAIN_TEXT_MODEL([features['text']])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "a906d7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caregiver_processed[0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "eaff03a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, int found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [226]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m MAIN_DATAFRAME \u001b[38;5;241m=\u001b[39m \u001b[43mtfds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcaregiver_processed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\asus\\anaconda3\\envs\\notebook\\lib\\site-packages\\tensorflow_datasets\\core\\as_dataframe.py:216\u001b[0m, in \u001b[0;36mas_dataframe\u001b[1;34m(ds, ds_info)\u001b[0m\n\u001b[0;32m    212\u001b[0m   ds \u001b[38;5;241m=\u001b[39m dataset_info\u001b[38;5;241m.\u001b[39mpack_as_supervised_ds(ds, ds_info)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;66;03m# Flatten the keys names, specs,... while keeping the feature key definition\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;66;03m# order\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m columns \u001b[38;5;241m=\u001b[39m \u001b[43m_make_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melement_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m rows \u001b[38;5;241m=\u001b[39m [_make_row_dict(ex, columns) \u001b[38;5;28;01mfor\u001b[39;00m ex \u001b[38;5;129;01min\u001b[39;00m dataset_utils\u001b[38;5;241m.\u001b[39mas_numpy(ds)]\n\u001b[0;32m    218\u001b[0m df \u001b[38;5;241m=\u001b[39m StyledDataFrame(rows)\n",
      "File \u001b[1;32mc:\\users\\asus\\anaconda3\\envs\\notebook\\lib\\site-packages\\tensorflow_datasets\\core\\as_dataframe.py:168\u001b[0m, in \u001b[0;36m_make_columns\u001b[1;34m(specs, ds_info)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_columns\u001b[39m(\n\u001b[0;32m    164\u001b[0m     specs: TreeDict[tf\u001b[38;5;241m.\u001b[39mTypeSpec],\n\u001b[0;32m    165\u001b[0m     ds_info: Optional[dataset_info\u001b[38;5;241m.\u001b[39mDatasetInfo],\n\u001b[0;32m    166\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[ColumnInfo]:\n\u001b[0;32m    167\u001b[0m   \u001b[38;5;124;03m\"\"\"Extract the columns info of the `panda.DataFrame`.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    169\u001b[0m       ColumnInfo\u001b[38;5;241m.\u001b[39mfrom_spec(path, ds_info)\n\u001b[0;32m    170\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m path, _ \u001b[38;5;129;01min\u001b[39;00m py_utils\u001b[38;5;241m.\u001b[39mflatten_with_path(specs)\n\u001b[0;32m    171\u001b[0m   ]\n",
      "File \u001b[1;32mc:\\users\\asus\\anaconda3\\envs\\notebook\\lib\\site-packages\\tensorflow_datasets\\core\\as_dataframe.py:169\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_columns\u001b[39m(\n\u001b[0;32m    164\u001b[0m     specs: TreeDict[tf\u001b[38;5;241m.\u001b[39mTypeSpec],\n\u001b[0;32m    165\u001b[0m     ds_info: Optional[dataset_info\u001b[38;5;241m.\u001b[39mDatasetInfo],\n\u001b[0;32m    166\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[ColumnInfo]:\n\u001b[0;32m    167\u001b[0m   \u001b[38;5;124;03m\"\"\"Extract the columns info of the `panda.DataFrame`.\"\"\"\u001b[39;00m\n\u001b[0;32m    168\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m--> 169\u001b[0m       \u001b[43mColumnInfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_spec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    170\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m path, _ \u001b[38;5;129;01min\u001b[39;00m py_utils\u001b[38;5;241m.\u001b[39mflatten_with_path(specs)\n\u001b[0;32m    171\u001b[0m   ]\n",
      "File \u001b[1;32mc:\\users\\asus\\anaconda3\\envs\\notebook\\lib\\site-packages\\tensorflow_datasets\\core\\as_dataframe.py:64\u001b[0m, in \u001b[0;36mColumnInfo.from_spec\u001b[1;34m(cls, path, ds_info)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_spec\u001b[39m(\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m     60\u001b[0m     path: Tuple[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m     61\u001b[0m     ds_info: Optional[dataset_info\u001b[38;5;241m.\u001b[39mDatasetInfo],\n\u001b[0;32m     62\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumnInfo\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     63\u001b[0m   \u001b[38;5;124;03m\"\"\"Formatter which filters values hard to read and format.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m   name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m   \u001b[38;5;66;03m# If ds_info is not provided, no formatting\u001b[39;00m\n\u001b[0;32m     67\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ds_info:\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# Could use the spec for a better formatting ?\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: sequence item 0: expected str instance, int found"
     ]
    }
   ],
   "source": [
    "MAIN_DATAFRAME = tfds.as_dataframe(caregiver_processed.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a892d1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [0.42, 2.12]\n",
    "data_np = np.asarray(data, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9c123af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.float32, name=None)>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.data.Dataset.from_tensor_slices(data_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a33ff7d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.42, 2.12], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "819e86cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c346e283",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
