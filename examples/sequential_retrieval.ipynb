{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ1C0j6bM8Ns"
      },
      "source": [
        "Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SCcCMGl4NOE0"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVhbbTC_NYJq"
      },
      "source": [
        "# Recommending movies: retrieval using a sequential model\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/recommenders/examples/sequential_retrieval\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/recommenders/blob/main/docs/examples/sequential_retrieval.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/recommenders/blob/main/docs/examples/sequential_retrieval.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/recommenders/docs/examples/sequential_retrieval.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSQBHTghPGcg"
      },
      "source": [
        "In this tutorial, we are going to build a sequential retrieval model. Sequential recommendation is a popular model that looks at a sequence of  items that users have interacted with previously and then predicts the next item. Here the order of the items within each sequence matters, so we are going to use a recurrent neural network to model the sequential relationship. For more details, please refer to this [GRU4Rec paper](https://arxiv.org/abs/1511.06939).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "447R2K8kRY0Z"
      },
      "source": [
        "## Imports\n",
        "\n",
        "First let's get our dependencies and imports out of the way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NM3uchF8deZL",
        "outputId": "bb5bb74e-8951-455c-9be2-45d09b2101a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 85 kB 2.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 462 kB 11.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 5.3 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q tensorflow-recommenders\n",
        "!pip install -q --upgrade tensorflow-datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HfpLMl1tc4OE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pprint\n",
        "import tempfile\n",
        "\n",
        "from typing import Dict, Text\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_recommenders as tfrs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GULCYkofR2pP"
      },
      "source": [
        "## Preparing the dataset\n",
        "\n",
        "Next, we need to prepare our dataset. We are going to leverage the [data generation utility](https://github.com/tensorflow/examples/blob/master/lite/examples/recommendation/ml/data/example_generation_movielens.py) in this [TensorFlow Lite On-device Recommendation reference app](https://www.tensorflow.org/lite/examples/recommendation/overview).\n",
        "\n",
        "MovieLens 1M data contains ratings.dat (*columns: UserID, MovieID, Rating, Timestamp*), and movies.dat (*columns: MovieID, Title, Genres*). The example generation script download the 1M dataset, takes both files, only keep ratings higher than 2, form user movie interaction timelines, sample activities as labels and 10 previous user activities as the context for prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sJiKu6hRc2H2",
        "outputId": "90e66076-9d46-4216-b41f-74bcae5ea8ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-20 08:30:07--  https://raw.githubusercontent.com/tensorflow/examples/master/lite/examples/recommendation/ml/data/example_generation_movielens.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18041 (18K) [text/plain]\n",
            "Saving to: ‘example_generation_movielens.py’\n",
            "\n",
            "\r          example_g   0%[                    ]       0  --.-KB/s               \rexample_generation_ 100%[===================>]  17.62K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-05-20 08:30:08 (40.3 MB/s) - ‘example_generation_movielens.py’ saved [18041/18041]\n",
            "\n",
            "I0520 08:30:11.569297 139806192351104 example_generation_movielens.py:460] Downloading and extracting data.\n",
            "Downloading data from https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
            "5922816/5917549 [==============================] - 0s 0us/step\n",
            "5931008/5917549 [==============================] - 0s 0us/step\n",
            "I0520 08:30:12.085531 139806192351104 example_generation_movielens.py:406] Reading data to dataframes.\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  return func(*args, **kwargs)\n",
            "I0520 08:30:17.738213 139806192351104 example_generation_movielens.py:408] Generating movie rating user timelines.\n",
            "I0520 08:30:28.806717 139806192351104 example_generation_movielens.py:410] Generating train and test examples.\n",
            "6040/6040 [==============================] - 120s 20ms/step\n",
            "I0520 08:32:30.323590 139806192351104 example_generation_movielens.py:421] Writing generated training examples.\n",
            "844195/844195 [==============================] - 19s 23us/step\n",
            "I0520 08:32:49.634758 139806192351104 example_generation_movielens.py:424] Writing generated testing examples.\n",
            "93799/93799 [==============================] - 2s 23us/step\n",
            "I0520 08:32:58.832880 139806192351104 example_generation_movielens.py:473] Generated dataset: {'train_size': 844195, 'test_size': 93799, 'train_file': 'data/examples/train_movielens_1m.tfrecord', 'test_file': 'data/examples/test_movielens_1m.tfrecord'}\n"
          ]
        }
      ],
      "source": [
        "!wget -nc https://raw.githubusercontent.com/tensorflow/examples/master/lite/examples/recommendation/ml/data/example_generation_movielens.py\n",
        "!python -m example_generation_movielens  --data_dir=data/raw  --output_dir=data/examples  --min_timeline_length=3  --max_context_length=10  --max_context_movie_genre_length=10  --min_rating=2  --train_data_fraction=0.9  --build_vocabs=False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5WEdiUNSmNb"
      },
      "source": [
        "Here is a sample of the generated dataset.\n",
        "\n",
        "```\n",
        "0 : {\n",
        "  features: {\n",
        "    feature: {\n",
        "      key  : \"context_movie_id\"\n",
        "      value: { int64_list: { value: [ 1124, 2240, 3251, ..., 1268 ] } }\n",
        "    }\n",
        "    feature: {\n",
        "      key  : \"context_movie_rating\"\n",
        "      value: { float_list: {value: [ 3.0, 3.0, 4.0, ..., 3.0 ] } }\n",
        "    }\n",
        "    feature: {\n",
        "      key  : \"context_movie_year\"\n",
        "      value: { int64_list: { value: [ 1981, 1980, 1985, ..., 1990 ] } }\n",
        "    }\n",
        "    feature: {\n",
        "      key  : \"context_movie_genre\"\n",
        "      value: { bytes_list: { value: [ \"Drama\", \"Drama\", \"Mystery\", ..., \"UNK\" ] } }\n",
        "    }\n",
        "    feature: {\n",
        "      key  : \"label_movie_id\"\n",
        "      value: { int64_list: { value: [ 3252 ] }  }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "```\n",
        "You can see that it includes a sequence of context movie IDs, and a label movie ID (next movie), plus context features such as movie year, rating and genre. \n",
        "\n",
        "In our case we will only be using the sequence of context movie IDs and the label movie ID. You can refer to the [Leveraging context features tutorial](https://www.tensorflow.org/recommenders/examples/context_features) to learn more about adding additional context features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "JQ2aLaCndSYP",
        "outputId": "5593186b-e5a6-448c-fef6-89dabc99ab64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'context_movie_id': array([b'2088', b'2411', b'2902', b'1985', b'2421', b'1983', b'1091',\n",
            "       b'2794', b'2735', b'2450'], dtype=object),\n",
            " 'context_movie_rating': array([b'4.000000', b'2.000000', b'2.000000', b'3.000000', b'2.000000',\n",
            "       b'2.000000', b'3.000000', b'2.000000', b'3.000000', b'3.000000'],\n",
            "      dtype=object),\n",
            " 'label_movie_id': array([b'1977'], dtype=object)}\n"
          ]
        }
      ],
      "source": [
        "train_filename = \"./data/examples/train_movielens_1m.tfrecord\"\n",
        "train = tf.data.TFRecordDataset(train_filename)\n",
        "\n",
        "test_filename = \"./data/examples/test_movielens_1m.tfrecord\"\n",
        "test = tf.data.TFRecordDataset(test_filename)\n",
        "\n",
        "feature_description = {\n",
        "    'context_movie_id': tf.io.FixedLenFeature([10], tf.int64, default_value=np.repeat(0, 10)),\n",
        "    'context_movie_rating': tf.io.FixedLenFeature([10], tf.float32, default_value=np.repeat(0, 10)),\n",
        "    'context_movie_year': tf.io.FixedLenFeature([10], tf.int64, default_value=np.repeat(1980, 10)),\n",
        "    'context_movie_genre': tf.io.FixedLenFeature([10], tf.string, default_value=np.repeat(\"Drama\", 10)),\n",
        "    'label_movie_id': tf.io.FixedLenFeature([1], tf.int64, default_value=0),\n",
        "}\n",
        "\n",
        "def _parse_function(example_proto):\n",
        "  return tf.io.parse_single_example(example_proto, feature_description)\n",
        "\n",
        "train_ds = train.map(_parse_function).map(lambda x: {\n",
        "    \"context_movie_id\": tf.strings.as_string(x[\"context_movie_id\"]),\n",
        "    \"context_movie_rating\":tf.strings.as_string(x[\"context_movie_rating\"]),\n",
        "    \"label_movie_id\": tf.strings.as_string(x[\"label_movie_id\"])\n",
        "})\n",
        "\n",
        "test_ds = test.map(_parse_function).map(lambda x: {\n",
        "    \"context_movie_id\": tf.strings.as_string(x[\"context_movie_id\"]),\n",
        "    \"context_movie_rating\":tf.strings.as_string(x[\"context_movie_rating\"]),\n",
        "    \"label_movie_id\": tf.strings.as_string(x[\"label_movie_id\"])\n",
        "})\n",
        "\n",
        "for x in train_ds.take(1).as_numpy_iterator():\n",
        "  pprint.pprint(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKmUecCVTf9Z"
      },
      "source": [
        "Now our train/test datasets include only a sequence of historical movie IDs and a label of next movie ID. Note that we use `[10]` as the shape of the features during tf.Example parsing because we specify 10 as the length of context features in the example generateion step.\n",
        "\n",
        "We need one more thing before we can start building the model - the vocabulary for our movie IDs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Szgmv8fvc7Tj"
      },
      "outputs": [],
      "source": [
        "movies = tfds.load(\"movielens/1m-movies\", split='train')\n",
        "movies = movies.map(lambda x: x[\"movie_id\"])\n",
        "movie_ids = movies.batch(1_000)\n",
        "unique_movie_ids = np.unique(np.concatenate(list(movie_ids)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxFmdiVxT8j_"
      },
      "source": [
        "## Implementing a sequential model\n",
        "\n",
        "In our [basic retrieval tutorial](https://www.tensorflow.org/recommenders/examples/basic_retrieval), we use one query tower for the user, and the candidate tow for the candidate movie. However, the two-tower architecture is generalizble and not limited to <user,item> pair. You can also use it to do item-to-item recommendation as we note in the [basic retrieval tutorial](https://www.tensorflow.org/recommenders/examples/basic_retrieval#item-to-item_recommendation).\n",
        "\n",
        "Here we are still going to use the two-tower architecture. Specificially, we use the query tower with a [Gated Recurrent Unit (GRU) layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU) to encode the sequence of historical movies, and keep the same candidate tower for the candidate movie. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "aP3OS_HPeefT"
      },
      "outputs": [],
      "source": [
        "embedding_dimension = 32\n",
        "\n",
        "query_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.StringLookup(\n",
        "      vocabulary=unique_movie_ids, mask_token=None),\n",
        "    tf.keras.layers.Embedding(len(unique_movie_ids) + 1, embedding_dimension), \n",
        "    tf.keras.layers.GRU(embedding_dimension),\n",
        "])\n",
        "\n",
        "candidate_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.StringLookup(\n",
        "      vocabulary=unique_movie_ids, mask_token=None),\n",
        "  tf.keras.layers.Embedding(len(unique_movie_ids) + 1, embedding_dimension)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ich7YzXXAWq"
      },
      "source": [
        "The metrics, task and full model are defined similar to the basic retrieval model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-KDYuhG9u9cq"
      },
      "outputs": [],
      "source": [
        "metrics = tfrs.metrics.FactorizedTopK(\n",
        "  candidates=movies.batch(128).map(candidate_model)\n",
        ")\n",
        "\n",
        "task = tfrs.tasks.Retrieval(\n",
        "  metrics=metrics\n",
        ")\n",
        "\n",
        "class Model(tfrs.Model):\n",
        "\n",
        "    def __init__(self, query_model, candidate_model):\n",
        "        super().__init__()\n",
        "        self._query_model = query_model\n",
        "        self._candidate_model = candidate_model\n",
        "\n",
        "        self._task = task\n",
        "\n",
        "    def compute_loss(self, features, training=False):\n",
        "        watch_history = features[\"context_movie_id\"]\n",
        "        watch_next_label = features[\"label_movie_id\"]\n",
        "\n",
        "        query_embedding = self._query_model(watch_history)       \n",
        "        candidate_embedding = self._candidate_model(watch_next_label)\n",
        "        \n",
        "        return self._task(query_embedding, candidate_embedding, compute_metrics=not training)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j22_GTTeXa_T"
      },
      "source": [
        "## Fitting and evaluating\n",
        "\n",
        "We can now compile, train and evaluate our sequential retrieval model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_c2wAqPVXYgz"
      },
      "outputs": [],
      "source": [
        "model = Model(query_model, candidate_model)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "9Wto55LJWuj0"
      },
      "outputs": [],
      "source": [
        "cached_train = train_ds.shuffle(10_000).batch(12800).cache()\n",
        "cached_test = test_ds.batch(2560).cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcXH5aDcWyJJ",
        "outputId": "43c69ca5-f188-4c19-e63f-e60c4ecef63c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "66/66 [==============================] - 117s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 108420.0125 - regularization_loss: 0.0000e+00 - total_loss: 108420.0125\n",
            "Epoch 2/3\n",
            " 1/66 [..............................] - ETA: 12s - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 102878.9688 - regularization_loss: 0.0000e+00 - total_loss: 102878.9688"
          ]
        }
      ],
      "source": [
        "model.fit(cached_train, epochs=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6aeXfXYw4Xtk"
      },
      "outputs": [],
      "source": [
        "model.evaluate(cached_test, return_dict=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ny2gMW3MdMKW"
      },
      "source": [
        "This concludes the sequential retrieval tutorial."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "sequential_retrieval.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}