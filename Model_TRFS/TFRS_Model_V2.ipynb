{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56d883eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow_recommenders as tfrs\n",
    "import tensorflow as tf\n",
    "from typing import Dict, Text\n",
    "\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40eb446c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "\n",
    "user_file = \"\\\\Data\\\\Combined Data.csv\"\n",
    "caregiver_file = \"\\\\Data\\\\Processed Caregiver Data.csv\"\n",
    "\n",
    "path = pathlib.Path().resolve()\n",
    "parent_path = path.parent.absolute()\n",
    "\n",
    "user_dataframe = pd.read_csv(str(parent_path) + user_file)\n",
    "caregiver_dataframe = pd.read_csv(str(parent_path) + caregiver_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "352ac361",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_masalah_user = np.unique(' '.join(user_dataframe['Tipe_Masalah']).split(' '))\n",
    "unique_masalah_caregiver = np.unique(' '.join(user_dataframe['Caregiver_Tipe_Masalah']).split(' '))\n",
    "np.delete(unique_masalah_caregiver, np.where(unique_masalah_caregiver == ''))\n",
    "unique_masalah_caregiver = np.delete(unique_masalah_caregiver, 0)\n",
    "\n",
    "unique_masalah_caregiver = unique_masalah_caregiver.tolist()\n",
    "\n",
    "for index, col in enumerate(unique_masalah_caregiver):\n",
    "        unique_masalah_caregiver[index] = 'Caregiver-'+col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa1c7286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_categorical_data(df, col='Tipe_Masalah'):\n",
    "    ### Join every string in every row, split the result, pull out the unique values.\n",
    "    genres = np.unique(' '.join(df[col]).split(' '))\n",
    "    ### Drop 'NA'\n",
    "    genres = np.delete(genres, np.where(genres == ''))\n",
    "    if(col=='Tipe_Masalah'):\n",
    "        for genre in genres:\n",
    "            df[genre] = df[col].str.contains(genre).astype('int')\n",
    "    else:\n",
    "        for genre in genres:\n",
    "            df['Caregiver-'+genre] = df[col].str.contains(genre).astype('int')\n",
    "    df.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "701cfd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_15916\\1340759235.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  user_dataframe.drop([\"USER_ID\"], 1,inplace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_15916\\1340759235.py:7: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  user_dataframe.drop([\"CAREGIVER_ID\"], 1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "convert_categorical_data(user_dataframe)\n",
    "convert_categorical_data(user_dataframe, col='Caregiver_Tipe_Masalah')\n",
    "convert_categorical_data(caregiver_dataframe, col='Caregiver_Tipe_Masalah')\n",
    "\n",
    "\n",
    "user_dataframe.drop([\"USER_ID\"], 1,inplace=True)\n",
    "user_dataframe.drop([\"CAREGIVER_ID\"], 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "118a8f59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Caregiver_Gender</th>\n",
       "      <th>Caregiver_Age</th>\n",
       "      <th>ADHD-Hiperaktif-dan-kurang-fokus</th>\n",
       "      <th>Depresi</th>\n",
       "      <th>Gangguan-kecemasan</th>\n",
       "      <th>Gangguan-makan</th>\n",
       "      <th>Gangguan-stres-pascatrauma</th>\n",
       "      <th>Skizofrenia</th>\n",
       "      <th>Caregiver-ADHD-Hiperaktif-dan-kurang-fokus</th>\n",
       "      <th>Caregiver-Depresi</th>\n",
       "      <th>Caregiver-Gangguan-kecemasan</th>\n",
       "      <th>Caregiver-Gangguan-makan</th>\n",
       "      <th>Caregiver-Gangguan-stres-pascatrauma</th>\n",
       "      <th>Caregiver-Skizofrenia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pria</td>\n",
       "      <td>33</td>\n",
       "      <td>Pria</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pria</td>\n",
       "      <td>33</td>\n",
       "      <td>Pria</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pria</td>\n",
       "      <td>29</td>\n",
       "      <td>Perempuan</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pria</td>\n",
       "      <td>29</td>\n",
       "      <td>Pria</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Perempuan</td>\n",
       "      <td>32</td>\n",
       "      <td>Pria</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender  Age Caregiver_Gender  Caregiver_Age  \\\n",
       "0       Pria   33             Pria             19   \n",
       "1       Pria   33             Pria             35   \n",
       "2       Pria   29        Perempuan             33   \n",
       "3       Pria   29             Pria             38   \n",
       "4  Perempuan   32             Pria             35   \n",
       "\n",
       "   ADHD-Hiperaktif-dan-kurang-fokus  Depresi  Gangguan-kecemasan  \\\n",
       "0                                 1        0                   0   \n",
       "1                                 1        0                   0   \n",
       "2                                 0        0                   0   \n",
       "3                                 0        0                   0   \n",
       "4                                 1        0                   1   \n",
       "\n",
       "   Gangguan-makan  Gangguan-stres-pascatrauma  Skizofrenia  \\\n",
       "0               0                           0            0   \n",
       "1               0                           0            0   \n",
       "2               1                           1            0   \n",
       "3               1                           1            0   \n",
       "4               0                           0            0   \n",
       "\n",
       "   Caregiver-ADHD-Hiperaktif-dan-kurang-fokus  Caregiver-Depresi  \\\n",
       "0                                           1                  0   \n",
       "1                                           1                  0   \n",
       "2                                           0                  0   \n",
       "3                                           1                  0   \n",
       "4                                           1                  0   \n",
       "\n",
       "   Caregiver-Gangguan-kecemasan  Caregiver-Gangguan-makan  \\\n",
       "0                             0                         0   \n",
       "1                             1                         0   \n",
       "2                             0                         1   \n",
       "3                             0                         1   \n",
       "4                             1                         0   \n",
       "\n",
       "   Caregiver-Gangguan-stres-pascatrauma  Caregiver-Skizofrenia  \n",
       "0                                     0                      0  \n",
       "1                                     1                      0  \n",
       "2                                     1                      0  \n",
       "3                                     0                      0  \n",
       "4                                     1                      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "user_dataframe.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ab5f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5049f45a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAREGIVER_ID</th>\n",
       "      <th>Caregiver_Gender</th>\n",
       "      <th>Caregiver_Age</th>\n",
       "      <th>Caregiver-ADHD-Hiperaktif-dan-kurang-fokus</th>\n",
       "      <th>Caregiver-Depresi</th>\n",
       "      <th>Caregiver-Gangguan-kecemasan</th>\n",
       "      <th>Caregiver-Gangguan-makan</th>\n",
       "      <th>Caregiver-Gangguan-stres-pascatrauma</th>\n",
       "      <th>Caregiver-Skizofrenia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Perempuan</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Pria</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Pria</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Perempuan</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Perempuan</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CAREGIVER_ID Caregiver_Gender  Caregiver_Age  \\\n",
       "0             1        Perempuan             28   \n",
       "1             2             Pria             33   \n",
       "2             3             Pria             19   \n",
       "3             4        Perempuan             18   \n",
       "4             5        Perempuan             36   \n",
       "\n",
       "   Caregiver-ADHD-Hiperaktif-dan-kurang-fokus  Caregiver-Depresi  \\\n",
       "0                                           1                  0   \n",
       "1                                           0                  1   \n",
       "2                                           1                  0   \n",
       "3                                           0                  0   \n",
       "4                                           0                  0   \n",
       "\n",
       "   Caregiver-Gangguan-kecemasan  Caregiver-Gangguan-makan  \\\n",
       "0                             0                         1   \n",
       "1                             0                         0   \n",
       "2                             0                         0   \n",
       "3                             0                         1   \n",
       "4                             1                         0   \n",
       "\n",
       "   Caregiver-Gangguan-stres-pascatrauma  Caregiver-Skizofrenia  \n",
       "0                                     1                      0  \n",
       "1                                     0                      1  \n",
       "2                                     0                      0  \n",
       "3                                     0                      1  \n",
       "4                                     0                      1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "caregiver_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e2ca4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9aa7bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "  dataframe = dataframe.copy()\n",
    "  ds = tf.data.Dataset.from_tensor_slices(dict(dataframe))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8651c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5# A small batch sized is used for demonstration purposes\n",
    "caregiver_ds = df_to_dataset(caregiver_dataframe, batch_size=batch_size,  shuffle=False)\n",
    "user_ds = df_to_dataset(user_dataframe, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2759a6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Caregiver-ADHD-Hiperaktif-dan-kurang-fokus', 'Caregiver-Depresi', 'Caregiver-Gangguan-kecemasan', 'Caregiver-Gangguan-makan', 'Caregiver-Gangguan-stres-pascatrauma', 'Caregiver-Skizofrenia']\n"
     ]
    }
   ],
   "source": [
    "feature_columns = []\n",
    "\n",
    "number_feature = [\"Age\"]\n",
    "number_feature += unique_masalah_user.tolist()\n",
    "print(unique_masalah_caregiver)\n",
    "# numeric cols\n",
    "for header in number_feature:\n",
    "    feature_columns.append(feature_column.numeric_column(header))\n",
    "\n",
    "age_feature = [\"Age\"]\n",
    "for col in age_feature:\n",
    "    age = feature_column.numeric_column(col)\n",
    "    age_buckets = feature_column.bucketized_column(age, boundaries=[17, 21, 25, 29, 33, 37, 41, 46])\n",
    "    feature_columns.append(age_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e66ceb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicator_columns\n",
    "indicator_column_names = ['Gender']\n",
    "for col_name in indicator_column_names:\n",
    "  categorical_column = feature_column.categorical_column_with_vocabulary_list(\n",
    "      col_name, user_dataframe[col_name].unique())\n",
    "  indicator_column = feature_column.indicator_column(categorical_column)\n",
    "  feature_columns.append(indicator_column)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "067961c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumericColumn(key='Age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='ADHD-Hiperaktif-dan-kurang-fokus', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='Depresi', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='Gangguan-kecemasan', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='Gangguan-makan', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='Gangguan-stres-pascatrauma', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='Skizofrenia', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "BucketizedColumn(source_column=NumericColumn(key='Age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(17, 21, 25, 29, 33, 37, 41, 46))\n",
      "IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Gender', vocabulary_list=('Pria', 'Perempuan'), dtype=tf.string, default_value=-1, num_oov_buckets=0))\n"
     ]
    }
   ],
   "source": [
    "for col in feature_columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c207a630",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_layer_user= tf.keras.layers.DenseFeatures(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4055c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Caregiver-ADHD-Hiperaktif-dan-kurang-fokus', 'Caregiver-Depresi', 'Caregiver-Gangguan-kecemasan', 'Caregiver-Gangguan-makan', 'Caregiver-Gangguan-stres-pascatrauma', 'Caregiver-Skizofrenia']\n"
     ]
    }
   ],
   "source": [
    "feature_columns = []\n",
    "\n",
    "number_feature = [\"Caregiver_Age\"]\n",
    "number_feature += unique_masalah_caregiver\n",
    "print(unique_masalah_caregiver)\n",
    "# numeric cols\n",
    "\n",
    "for header in number_feature:\n",
    "    feature_columns.append(feature_column.numeric_column(header))\n",
    "\n",
    "age_feature = [\"Caregiver_Age\"]\n",
    "for col in age_feature:\n",
    "    age = feature_column.numeric_column(col)\n",
    "    age_buckets = feature_column.bucketized_column(age, boundaries=[17, 21, 25, 29, 33, 37, 41, 46])\n",
    "    feature_columns.append(age_buckets)\n",
    "\n",
    "col_name = 'Caregiver_Gender'\n",
    "categorical_column = feature_column.categorical_column_with_vocabulary_list(\n",
    "      col_name, user_dataframe[col_name].unique())\n",
    "indicator_column = feature_column.indicator_column(categorical_column)\n",
    "feature_columns.append(indicator_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6eb0ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_layer_caregiver= tf.keras.layers.DenseFeatures(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecf815dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecomendModel(tfrs.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    embedding_dimension = 32\n",
    "\n",
    "    # Set up a model for representing users.\n",
    "    self.user_model = tf.keras.Sequential([\n",
    "        feature_layer_user,\n",
    "        layers.Dense(64),\n",
    "        layers.Dense(32)\n",
    "    ])\n",
    "\n",
    "    # Set up a model for representing caregiver.\n",
    "    self.caregiver_model = tf.keras.Sequential([\n",
    "        feature_layer_caregiver,\n",
    "        layers.Dense(64),\n",
    "        layers.Dense(32)\n",
    "    ])\n",
    "\n",
    "    # Set up a task to optimize the model and compute metrics.\n",
    "    self.task = tfrs.tasks.Retrieval(\n",
    "      metrics=tfrs.metrics.FactorizedTopK(\n",
    "        candidates=caregiver_ds.batch(5).map(self.caregiver_model)\n",
    "      )\n",
    "    )\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "    \n",
    "    caregiver_features = ['Caregiver_Gender', 'Caregiver_Age',  'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus', 'Caregiver-Depresi', 'Caregiver-Gangguan-kecemasan', 'Caregiver-Gangguan-makan', 'Caregiver-Gangguan-stres-pascatrauma', 'Caregiver-Skizofrenia']\n",
    "    user_features = ['Gender', 'Age', 'ADHD-Hiperaktif-dan-kurang-fokus', 'Depresi', 'Gangguan-kecemasan', 'Gangguan-makan','Gangguan-stres-pascatrauma', 'Skizofrenia']\n",
    "    \n",
    "    \n",
    "    # We pick out the user features and pass them into the user model.\n",
    "    \n",
    "    user_embeddings = self.user_model({\n",
    "        'Age':features['Age'],\n",
    "        'Gender':features['Gender'],\n",
    "        'ADHD-Hiperaktif-dan-kurang-fokus':features['ADHD-Hiperaktif-dan-kurang-fokus'],\n",
    "        'Depresi':features['Depresi'],\n",
    "        'Gangguan-kecemasan':features['Gangguan-kecemasan'],\n",
    "        'Gangguan-makan':features['Gangguan-makan'],\n",
    "        'Gangguan-stres-pascatrauma':features['Gangguan-stres-pascatrauma'],\n",
    "        'Skizofrenia':features['Skizofrenia']\n",
    "    })\n",
    "    # And pick out the movie features and pass them into the movie model,\n",
    "    # getting embeddings back.\n",
    "    positive_movie_embeddings = self.caregiver_model({\n",
    "        'Caregiver_Age':features['Caregiver_Age'],\n",
    "        'Caregiver_Gender':features['Caregiver_Gender'],\n",
    "        'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus':features['Caregiver-ADHD-Hiperaktif-dan-kurang-fokus'],\n",
    "        'Caregiver-Depresi':features['Caregiver-Depresi'],\n",
    "        'Caregiver-Gangguan-kecemasan':features['Caregiver-Gangguan-kecemasan'],\n",
    "        'Caregiver-Gangguan-makan':features['Caregiver-Gangguan-makan'],\n",
    "        'Caregiver-Gangguan-stres-pascatrauma':features['Caregiver-Gangguan-stres-pascatrauma'],\n",
    "        'Caregiver-Skizofrenia':features['Caregiver-Skizofrenia']\n",
    "        \n",
    "    })\n",
    "    \n",
    "\n",
    "    # The task computes the loss and the metrics.\n",
    "\n",
    "    return self.task(user_embeddings, positive_movie_embeddings, compute_metrics=not training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acc13ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "caregiver_features = ['Caregiver_Gender', 'Caregiver_Age',  'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus', 'Caregiver-Depresi', 'Caregiver-Gangguan-kecemasan', 'Caregiver-Gangguan-makan', 'Caregiver-Gangguan-stres-pascatrauma', 'Caregiver-Skizofrenia']\n",
    "user_features = ['Gender', 'Age', 'ADHD-Hiperaktif-dan-kurang-fokus', 'Depresi', 'Gangguan-kecemasan', 'Gangguan-makan','Gangguan-stres-pascatrauma', 'Skizofrenia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f92c75f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every feature: ['CAREGIVER_ID', 'Caregiver_Gender', 'Caregiver_Age', 'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus', 'Caregiver-Depresi', 'Caregiver-Gangguan-kecemasan', 'Caregiver-Gangguan-makan', 'Caregiver-Gangguan-stres-pascatrauma', 'Caregiver-Skizofrenia']\n",
      "A batch of ages: tf.Tensor([1 0 1 0 0], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for feature_batch in caregiver_ds.take(1):\n",
    "  print('Every feature:', list(feature_batch.keys()))\n",
    "  print('A batch of ages:', feature_batch['Caregiver-ADHD-Hiperaktif-dan-kurang-fokus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9916b33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asus\\anaconda3\\envs\\notebook\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eef5f320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_partitions_tf(ds, ds_size, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):\n",
    "    assert (train_split + test_split + val_split) == 1\n",
    "    \n",
    "    if shuffle:\n",
    "        # Specify seed to always have the same split distribution between runs\n",
    "        ds = ds.shuffle(shuffle_size, seed=12)\n",
    "    \n",
    "    train_size = int(train_split * ds_size)\n",
    "    val_size = int(val_split * ds_size)\n",
    "    \n",
    "    train_ds = ds.take(train_size)    \n",
    "    val_ds = ds.skip(train_size).take(val_size)\n",
    "    test_ds = ds.skip(train_size).skip(val_size)\n",
    "    \n",
    "    return train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7cb52f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = get_dataset_partitions_tf(user_ds, 200, train_split=0.8, val_split=0.2, test_split=0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0694d02e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'CAREGIVER_ID': <tf.Tensor 'args_0:0' shape=(None, None) dtype=int64>, 'Caregiver_Gender': <tf.Tensor 'args_8:0' shape=(None, None) dtype=string>, 'Caregiver_Age': <tf.Tensor 'args_7:0' shape=(None, None) dtype=int64>, 'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus': <tf.Tensor 'args_1:0' shape=(None, None) dtype=int32>, 'Caregiver-Depresi': <tf.Tensor 'args_2:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-kecemasan': <tf.Tensor 'args_3:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-makan': <tf.Tensor 'args_4:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-stres-pascatrauma': <tf.Tensor 'args_5:0' shape=(None, None) dtype=int32>, 'Caregiver-Skizofrenia': <tf.Tensor 'args_6:0' shape=(None, None) dtype=int32>}. Consider rewriting this model with the Functional API.\n",
      "Epoch 1/50\n",
      "AAAAAAAAAAAAAAAAAA\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'Age': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=int64>, 'Gender': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=string>, 'ADHD-Hiperaktif-dan-kurang-fokus': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int32>, 'Depresi': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=int32>, 'Gangguan-kecemasan': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=int32>, 'Gangguan-makan': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=int32>, 'Gangguan-stres-pascatrauma': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=int32>, 'Skizofrenia': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=int32>}. Consider rewriting this model with the Functional API.\n",
      "BBBBBBBBBBBBBB\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'Caregiver_Age': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=int64>, 'Caregiver_Gender': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=string>, 'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=int32>, 'Caregiver-Depresi': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=int32>, 'Caregiver-Gangguan-kecemasan': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=int32>, 'Caregiver-Gangguan-makan': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=int32>, 'Caregiver-Gangguan-stres-pascatrauma': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=int32>, 'Caregiver-Skizofrenia': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=int32>}. Consider rewriting this model with the Functional API.\n",
      "AAAAAAAAAAAAAAAAAA\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'Age': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=int64>, 'Gender': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=string>, 'ADHD-Hiperaktif-dan-kurang-fokus': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int32>, 'Depresi': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=int32>, 'Gangguan-kecemasan': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=int32>, 'Gangguan-makan': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=int32>, 'Gangguan-stres-pascatrauma': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=int32>, 'Skizofrenia': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=int32>}. Consider rewriting this model with the Functional API.\n",
      "BBBBBBBBBBBBBB\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'Caregiver_Age': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=int64>, 'Caregiver_Gender': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=string>, 'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=int32>, 'Caregiver-Depresi': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=int32>, 'Caregiver-Gangguan-kecemasan': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=int32>, 'Caregiver-Gangguan-makan': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=int32>, 'Caregiver-Gangguan-stres-pascatrauma': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=int32>, 'Caregiver-Skizofrenia': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=int32>}. Consider rewriting this model with the Functional API.\n",
      "40/40 [==============================] - 1s 10ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 55.9835 - regularization_loss: 0.0000e+00 - total_loss: 55.9835\n",
      "Epoch 2/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 19.1213 - regularization_loss: 0.0000e+00 - total_loss: 19.1213\n",
      "Epoch 3/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 14.3867 - regularization_loss: 0.0000e+00 - total_loss: 14.3867\n",
      "Epoch 4/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 9.4367 - regularization_loss: 0.0000e+00 - total_loss: 9.4367\n",
      "Epoch 5/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 8.8881 - regularization_loss: 0.0000e+00 - total_loss: 8.8881\n",
      "Epoch 6/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 8.7451 - regularization_loss: 0.0000e+00 - total_loss: 8.7451\n",
      "Epoch 7/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 15.0362 - regularization_loss: 0.0000e+00 - total_loss: 15.0362\n",
      "Epoch 8/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 11.2936 - regularization_loss: 0.0000e+00 - total_loss: 11.2936\n",
      "Epoch 9/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 9.3130 - regularization_loss: 0.0000e+00 - total_loss: 9.3130\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 10.3431 - regularization_loss: 0.0000e+00 - total_loss: 10.3431\n",
      "Epoch 11/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 12.5725 - regularization_loss: 0.0000e+00 - total_loss: 12.5725\n",
      "Epoch 12/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 9.2427 - regularization_loss: 0.0000e+00 - total_loss: 9.2427\n",
      "Epoch 13/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 8.3084 - regularization_loss: 0.0000e+00 - total_loss: 8.3084\n",
      "Epoch 14/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 8.3862 - regularization_loss: 0.0000e+00 - total_loss: 8.3862\n",
      "Epoch 15/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 7.9318 - regularization_loss: 0.0000e+00 - total_loss: 7.9318\n",
      "Epoch 16/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 8.2523 - regularization_loss: 0.0000e+00 - total_loss: 8.2523\n",
      "Epoch 17/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 8.4758 - regularization_loss: 0.0000e+00 - total_loss: 8.4758\n",
      "Epoch 18/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 7.6664 - regularization_loss: 0.0000e+00 - total_loss: 7.6664\n",
      "Epoch 19/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 7.9638 - regularization_loss: 0.0000e+00 - total_loss: 7.9638\n",
      "Epoch 20/50\n",
      "40/40 [==============================] - 0s 10ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 7.2972 - regularization_loss: 0.0000e+00 - total_loss: 7.2972\n",
      "Epoch 21/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 7.0416 - regularization_loss: 0.0000e+00 - total_loss: 7.0416\n",
      "Epoch 22/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6.9881 - regularization_loss: 0.0000e+00 - total_loss: 6.9881\n",
      "Epoch 23/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 7.0604 - regularization_loss: 0.0000e+00 - total_loss: 7.0604\n",
      "Epoch 24/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 7.8726 - regularization_loss: 0.0000e+00 - total_loss: 7.8726\n",
      "Epoch 25/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 7.5456 - regularization_loss: 0.0000e+00 - total_loss: 7.5456\n",
      "Epoch 26/50\n",
      "40/40 [==============================] - 0s 10ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 7.0170 - regularization_loss: 0.0000e+00 - total_loss: 7.0170\n",
      "Epoch 27/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6.7139 - regularization_loss: 0.0000e+00 - total_loss: 6.7139\n",
      "Epoch 28/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6.6862 - regularization_loss: 0.0000e+00 - total_loss: 6.6862\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 7.1830 - regularization_loss: 0.0000e+00 - total_loss: 7.1830\n",
      "Epoch 30/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6.8100 - regularization_loss: 0.0000e+00 - total_loss: 6.8100\n",
      "Epoch 31/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6.8961 - regularization_loss: 0.0000e+00 - total_loss: 6.8961\n",
      "Epoch 32/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6.3535 - regularization_loss: 0.0000e+00 - total_loss: 6.3535\n",
      "Epoch 33/50\n",
      "40/40 [==============================] - 0s 10ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6.5686 - regularization_loss: 0.0000e+00 - total_loss: 6.5686\n",
      "Epoch 34/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6.7440 - regularization_loss: 0.0000e+00 - total_loss: 6.7440\n",
      "Epoch 35/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6.7361 - regularization_loss: 0.0000e+00 - total_loss: 6.7361\n",
      "Epoch 36/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6.8821 - regularization_loss: 0.0000e+00 - total_loss: 6.8821\n",
      "Epoch 37/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6.7806 - regularization_loss: 0.0000e+00 - total_loss: 6.7806\n",
      "Epoch 38/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6.3678 - regularization_loss: 0.0000e+00 - total_loss: 6.3678\n",
      "Epoch 39/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6.5726 - regularization_loss: 0.0000e+00 - total_loss: 6.5726\n",
      "Epoch 40/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6.5324 - regularization_loss: 0.0000e+00 - total_loss: 6.5324\n",
      "Epoch 41/50\n",
      "40/40 [==============================] - 0s 10ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6.4580 - regularization_loss: 0.0000e+00 - total_loss: 6.4580\n",
      "Epoch 42/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6.0927 - regularization_loss: 0.0000e+00 - total_loss: 6.0927\n",
      "Epoch 43/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6.3275 - regularization_loss: 0.0000e+00 - total_loss: 6.3275\n",
      "Epoch 44/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6.6228 - regularization_loss: 0.0000e+00 - total_loss: 6.6228\n",
      "Epoch 45/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6.6455 - regularization_loss: 0.0000e+00 - total_loss: 6.6455\n",
      "Epoch 46/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6.4623 - regularization_loss: 0.0000e+00 - total_loss: 6.4623\n",
      "Epoch 47/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6.5670 - regularization_loss: 0.0000e+00 - total_loss: 6.5670\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6.6246 - regularization_loss: 0.0000e+00 - total_loss: 6.6246\n",
      "Epoch 49/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6.4869 - regularization_loss: 0.0000e+00 - total_loss: 6.4869\n",
      "Epoch 50/50\n",
      "40/40 [==============================] - 0s 9ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6.5185 - regularization_loss: 0.0000e+00 - total_loss: 6.5185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x220229886d0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RecomendModel()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_ds,\n",
    "          validation_data=val_ds,\n",
    "          epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ee3cb34",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\asus\\anaconda3\\envs\\notebook\\lib\\site-packages\\keras\\engine\\training.py:2775\u001b[0m, in \u001b[0;36mModel.summary\u001b[1;34m(self, line_length, positions, print_fn, expand_nested, show_trainable)\u001b[0m\n\u001b[0;32m   2753\u001b[0m \u001b[38;5;124;03m\"\"\"Prints a string summary of the network.\u001b[39;00m\n\u001b[0;32m   2754\u001b[0m \n\u001b[0;32m   2755\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2772\u001b[0m \u001b[38;5;124;03m    ValueError: if `summary()` is called before the model is built.\u001b[39;00m\n\u001b[0;32m   2773\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[1;32m-> 2775\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2776\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis model has not yet been built. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2777\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBuild the model first by calling `build()` or by calling \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2778\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe model on a batch of data.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   2779\u001b[0m layer_utils\u001b[38;5;241m.\u001b[39mprint_summary(\n\u001b[0;32m   2780\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2781\u001b[0m     line_length\u001b[38;5;241m=\u001b[39mline_length,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2784\u001b[0m     expand_nested\u001b[38;5;241m=\u001b[39mexpand_nested,\n\u001b[0;32m   2785\u001b[0m     show_trainable\u001b[38;5;241m=\u001b[39mshow_trainable)\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5420b2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every feature: ['CAREGIVER_ID', 'Caregiver_Gender', 'Caregiver_Age', 'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus', 'Caregiver-Depresi', 'Caregiver-Gangguan-kecemasan', 'Caregiver-Gangguan-makan', 'Caregiver-Gangguan-stres-pascatrauma', 'Caregiver-Skizofrenia']\n",
      "Every feature: ['CAREGIVER_ID', 'Caregiver_Gender', 'Caregiver_Age', 'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus', 'Caregiver-Depresi', 'Caregiver-Gangguan-kecemasan', 'Caregiver-Gangguan-makan', 'Caregiver-Gangguan-stres-pascatrauma', 'Caregiver-Skizofrenia']\n",
      "Every feature: ['CAREGIVER_ID', 'Caregiver_Gender', 'Caregiver_Age', 'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus', 'Caregiver-Depresi', 'Caregiver-Gangguan-kecemasan', 'Caregiver-Gangguan-makan', 'Caregiver-Gangguan-stres-pascatrauma', 'Caregiver-Skizofrenia']\n",
      "Every feature: ['CAREGIVER_ID', 'Caregiver_Gender', 'Caregiver_Age', 'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus', 'Caregiver-Depresi', 'Caregiver-Gangguan-kecemasan', 'Caregiver-Gangguan-makan', 'Caregiver-Gangguan-stres-pascatrauma', 'Caregiver-Skizofrenia']\n",
      "Every feature: ['CAREGIVER_ID', 'Caregiver_Gender', 'Caregiver_Age', 'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus', 'Caregiver-Depresi', 'Caregiver-Gangguan-kecemasan', 'Caregiver-Gangguan-makan', 'Caregiver-Gangguan-stres-pascatrauma', 'Caregiver-Skizofrenia']\n",
      "Every feature: ['CAREGIVER_ID', 'Caregiver_Gender', 'Caregiver_Age', 'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus', 'Caregiver-Depresi', 'Caregiver-Gangguan-kecemasan', 'Caregiver-Gangguan-makan', 'Caregiver-Gangguan-stres-pascatrauma', 'Caregiver-Skizofrenia']\n"
     ]
    }
   ],
   "source": [
    "for feature_batch in caregiver_ds:\n",
    "  print('Every feature:', list(feature_batch.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6099e2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'CAREGIVER_ID': <tf.Tensor 'args_0:0' shape=(None,) dtype=int64>, 'Caregiver_Gender': <tf.Tensor 'args_8:0' shape=(None,) dtype=string>, 'Caregiver_Age': <tf.Tensor 'args_7:0' shape=(None,) dtype=int64>, 'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus': <tf.Tensor 'args_1:0' shape=(None,) dtype=int32>, 'Caregiver-Depresi': <tf.Tensor 'args_2:0' shape=(None,) dtype=int32>, 'Caregiver-Gangguan-kecemasan': <tf.Tensor 'args_3:0' shape=(None,) dtype=int32>, 'Caregiver-Gangguan-makan': <tf.Tensor 'args_4:0' shape=(None,) dtype=int32>, 'Caregiver-Gangguan-stres-pascatrauma': <tf.Tensor 'args_5:0' shape=(None,) dtype=int32>, 'Caregiver-Skizofrenia': <tf.Tensor 'args_6:0' shape=(None,) dtype=int32>}. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.layers.factorized_top_k.BruteForce at 0x1e21200e400>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brute_force = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "brute_force.index_from_dataset(  \n",
    "       caregiver_ds.map(lambda features: (features['CAREGIVER_ID'], model.caregiver_model(features)))\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ea1164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5dc7f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d510961b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Gender': ['Pria'], 'Age': [30], 'ADHD-Hiperaktif-dan-kurang-fokus': [0], 'Depresi': [1], 'Gangguan-kecemasan': [0], 'Gangguan-makan': [0], 'Gangguan-stres-pascatrauma': [1], 'Skizofrenia': [0]}\n"
     ]
    }
   ],
   "source": [
    "a =['Gender', 'Age', 'ADHD-Hiperaktif-dan-kurang-fokus', 'Depresi', 'Gangguan-kecemasan', 'Gangguan-makan','Gangguan-stres-pascatrauma', 'Skizofrenia']\n",
    "value = ['Pria', 30, 0, 1, 0, 0, 1, 0]\n",
    "dictionary_Test = dict((el,([value[ix]])) for ix,el in enumerate(a))\n",
    "print(dictionary_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce0b86bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Caregiver_Gender': ['Pria'], 'Caregiver_Age': [30], 'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus': [0], 'Caregiver-Depresi': [1], 'Caregiver-Gangguan-kecemasan': [0], 'Caregiver-Gangguan-makan': [0], 'Caregiver-Gangguan-stres-pascatrauma': [1], 'Caregiver-Skizofrenia': [0]}\n"
     ]
    }
   ],
   "source": [
    "a =['Caregiver_Gender', 'Caregiver_Age', 'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus', 'Caregiver-Depresi', 'Caregiver-Gangguan-kecemasan', 'Caregiver-Gangguan-makan','Caregiver-Gangguan-stres-pascatrauma', 'Caregiver-Skizofrenia']\n",
    "value = ['Pria', 30, 0, 1, 0, 0, 1, 0]\n",
    "dictionary_Test_Caregiver = dict((el,([value[ix]])) for ix,el in enumerate(a))\n",
    "print(dictionary_Test_Caregiver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab7cbaaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'Gender': ['Pria'], 'Age': [<tf.Tensor: shape=(), dtype=int32, numpy=30>], 'ADHD-Hiperaktif-dan-kurang-fokus': [<tf.Tensor: shape=(), dtype=int32, numpy=0>], 'Depresi': [<tf.Tensor: shape=(), dtype=int32, numpy=1>], 'Gangguan-kecemasan': [<tf.Tensor: shape=(), dtype=int32, numpy=0>], 'Gangguan-makan': [<tf.Tensor: shape=(), dtype=int32, numpy=0>], 'Gangguan-stres-pascatrauma': [<tf.Tensor: shape=(), dtype=int32, numpy=1>], 'Skizofrenia': [<tf.Tensor: shape=(), dtype=int32, numpy=0>]}. Consider rewriting this model with the Functional API.\n",
      "Top recommendations: [11 24]\n"
     ]
    }
   ],
   "source": [
    "# Get predictions for user 42.\n",
    "a, titles = brute_force(dictionary_Test, k=2)\n",
    "print(f\"Top recommendations: {titles[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab27a59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'Caregiver_Gender': ['Pria'], 'Caregiver_Age': [<tf.Tensor: shape=(), dtype=int32, numpy=30>], 'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus': [<tf.Tensor: shape=(), dtype=int32, numpy=0>], 'Caregiver-Depresi': [<tf.Tensor: shape=(), dtype=int32, numpy=1>], 'Caregiver-Gangguan-kecemasan': [<tf.Tensor: shape=(), dtype=int32, numpy=0>], 'Caregiver-Gangguan-makan': [<tf.Tensor: shape=(), dtype=int32, numpy=0>], 'Caregiver-Gangguan-stres-pascatrauma': [<tf.Tensor: shape=(), dtype=int32, numpy=1>], 'Caregiver-Skizofrenia': [<tf.Tensor: shape=(), dtype=int32, numpy=0>]}. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.05826065, -0.38476425, -0.40455246,  0.15347545, -0.9849558 ,\n",
       "         0.6024401 ,  0.87596047,  1.9819466 , -0.11216472,  0.64404947,\n",
       "        -0.7053842 , -0.3897458 ,  1.7571347 ,  0.18089873,  0.37688297,\n",
       "        -0.23129736,  0.15130869,  0.7019512 , -0.7580117 ,  0.58990633,\n",
       "         0.29467872, -0.7741382 , -0.5695449 ,  0.23612425, -0.42787105,\n",
       "        -0.31546247, -1.6128621 , -1.0114098 , -1.0022382 ,  2.004491  ,\n",
       "        -0.13656217, -0.55576605]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = model.caregiver_model(dictionary_Test_Caregiver)\n",
    "tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7089edc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'Gender': ['Pria'], 'Age': [<tf.Tensor: shape=(), dtype=int32, numpy=30>], 'ADHD-Hiperaktif-dan-kurang-fokus': [<tf.Tensor: shape=(), dtype=int32, numpy=0>], 'Depresi': [<tf.Tensor: shape=(), dtype=int32, numpy=1>], 'Gangguan-kecemasan': [<tf.Tensor: shape=(), dtype=int32, numpy=0>], 'Gangguan-makan': [<tf.Tensor: shape=(), dtype=int32, numpy=0>], 'Gangguan-stres-pascatrauma': [<tf.Tensor: shape=(), dtype=int32, numpy=1>], 'Skizofrenia': [<tf.Tensor: shape=(), dtype=int32, numpy=0>]}. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.40695393, -0.75670004,  0.44062   ,  0.03337876,  0.3510351 ,\n",
       "        -0.8266126 ,  0.47377875, -0.00593777,  0.28147358,  0.50841457,\n",
       "         0.25378108,  0.0127746 , -0.23315774,  0.57836205, -0.45241782,\n",
       "        -0.4480724 , -0.38965246,  1.5780258 , -1.0968956 , -0.15245171,\n",
       "        -0.29448467,  0.30920178,  0.26669517, -0.49621144,  0.512001  ,\n",
       "        -1.1214398 , -0.95028883,  0.18500848, -0.31177223,  1.1428536 ,\n",
       "        -0.35230073,  0.325258  ]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = model.user_model(dictionary_Test)\n",
    "tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca36293e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'CAREGIVER_ID': <tf.Tensor 'args_0:0' shape=(None, None) dtype=int64>, 'Caregiver_Gender': <tf.Tensor 'args_8:0' shape=(None, None) dtype=string>, 'Caregiver_Age': <tf.Tensor 'args_7:0' shape=(None, None) dtype=int64>, 'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus': <tf.Tensor 'args_1:0' shape=(None, None) dtype=int32>, 'Caregiver-Depresi': <tf.Tensor 'args_2:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-kecemasan': <tf.Tensor 'args_3:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-makan': <tf.Tensor 'args_4:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-stres-pascatrauma': <tf.Tensor 'args_5:0' shape=(None, None) dtype=int32>, 'Caregiver-Skizofrenia': <tf.Tensor 'args_6:0' shape=(None, None) dtype=int32>}. Consider rewriting this model with the Functional API.\n"
     ]
    }
   ],
   "source": [
    "processed_ds = caregiver_ds.batch(5).map(model.caregiver_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9770b62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Model.save of <__main__.RecomendModel object at 0x000001E21200E910>>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8932037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset element_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b0f03cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'Age': <tf.Tensor 'Age:0' shape=(None,) dtype=int64>, 'Gender': <tf.Tensor 'Gender:0' shape=(None,) dtype=string>, 'ADHD-Hiperaktif-dan-kurang-fokus': <tf.Tensor 'ADHD-Hiperaktif-dan-kurang-fokus:0' shape=(None,) dtype=int32>, 'Depresi': <tf.Tensor 'Depresi:0' shape=(None,) dtype=int32>, 'Gangguan-kecemasan': <tf.Tensor 'Gangguan-kecemasan:0' shape=(None,) dtype=int32>, 'Gangguan-makan': <tf.Tensor 'Gangguan-makan:0' shape=(None,) dtype=int32>, 'Gangguan-stres-pascatrauma': <tf.Tensor 'Gangguan-stres-pascatrauma:0' shape=(None,) dtype=int32>, 'Skizofrenia': <tf.Tensor 'Skizofrenia:0' shape=(None,) dtype=int32>}. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'Age': <tf.Tensor 'inputs_1:0' shape=(None,) dtype=int64>, 'Gender': <tf.Tensor 'inputs_6:0' shape=(None,) dtype=string>, 'ADHD-Hiperaktif-dan-kurang-fokus': <tf.Tensor 'inputs:0' shape=(None,) dtype=int32>, 'Depresi': <tf.Tensor 'inputs_2:0' shape=(None,) dtype=int32>, 'Gangguan-kecemasan': <tf.Tensor 'inputs_3:0' shape=(None,) dtype=int32>, 'Gangguan-makan': <tf.Tensor 'inputs_4:0' shape=(None,) dtype=int32>, 'Gangguan-stres-pascatrauma': <tf.Tensor 'inputs_5:0' shape=(None,) dtype=int32>, 'Skizofrenia': <tf.Tensor 'inputs_7:0' shape=(None,) dtype=int32>}. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'Age': <tf.Tensor 'inputs_1:0' shape=(None,) dtype=int64>, 'Gender': <tf.Tensor 'inputs_6:0' shape=(None,) dtype=string>, 'ADHD-Hiperaktif-dan-kurang-fokus': <tf.Tensor 'inputs:0' shape=(None,) dtype=int32>, 'Depresi': <tf.Tensor 'inputs_2:0' shape=(None,) dtype=int32>, 'Gangguan-kecemasan': <tf.Tensor 'inputs_3:0' shape=(None,) dtype=int32>, 'Gangguan-makan': <tf.Tensor 'inputs_4:0' shape=(None,) dtype=int32>, 'Gangguan-stres-pascatrauma': <tf.Tensor 'inputs_5:0' shape=(None,) dtype=int32>, 'Skizofrenia': <tf.Tensor 'inputs_7:0' shape=(None,) dtype=int32>}. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'Age': <tf.Tensor 'Age:0' shape=(None,) dtype=int64>, 'Gender': <tf.Tensor 'Gender:0' shape=(None,) dtype=string>, 'ADHD-Hiperaktif-dan-kurang-fokus': <tf.Tensor 'ADHD-Hiperaktif-dan-kurang-fokus:0' shape=(None,) dtype=int32>, 'Depresi': <tf.Tensor 'Depresi:0' shape=(None,) dtype=int32>, 'Gangguan-kecemasan': <tf.Tensor 'Gangguan-kecemasan:0' shape=(None,) dtype=int32>, 'Gangguan-makan': <tf.Tensor 'Gangguan-makan:0' shape=(None,) dtype=int32>, 'Gangguan-stres-pascatrauma': <tf.Tensor 'Gangguan-stres-pascatrauma:0' shape=(None,) dtype=int32>, 'Skizofrenia': <tf.Tensor 'Skizofrenia:0' shape=(None,) dtype=int32>}. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'Age': <tf.Tensor 'Age:0' shape=(None,) dtype=int64>, 'Gender': <tf.Tensor 'Gender:0' shape=(None,) dtype=string>, 'ADHD-Hiperaktif-dan-kurang-fokus': <tf.Tensor 'ADHD-Hiperaktif-dan-kurang-fokus:0' shape=(None,) dtype=int32>, 'Depresi': <tf.Tensor 'Depresi:0' shape=(None,) dtype=int32>, 'Gangguan-kecemasan': <tf.Tensor 'Gangguan-kecemasan:0' shape=(None,) dtype=int32>, 'Gangguan-makan': <tf.Tensor 'Gangguan-makan:0' shape=(None,) dtype=int32>, 'Gangguan-stres-pascatrauma': <tf.Tensor 'Gangguan-stres-pascatrauma:0' shape=(None,) dtype=int32>, 'Skizofrenia': <tf.Tensor 'Skizofrenia:0' shape=(None,) dtype=int32>}. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'Age': <tf.Tensor 'inputs/Age:0' shape=(None,) dtype=int64>, 'Gender': <tf.Tensor 'inputs/Gender:0' shape=(None,) dtype=string>, 'ADHD-Hiperaktif-dan-kurang-fokus': <tf.Tensor 'inputs/ADHD-Hiperaktif-dan-kurang-fokus:0' shape=(None,) dtype=int32>, 'Depresi': <tf.Tensor 'inputs/Depresi:0' shape=(None,) dtype=int32>, 'Gangguan-kecemasan': <tf.Tensor 'inputs/Gangguan-kecemasan:0' shape=(None,) dtype=int32>, 'Gangguan-makan': <tf.Tensor 'inputs/Gangguan-makan:0' shape=(None,) dtype=int32>, 'Gangguan-stres-pascatrauma': <tf.Tensor 'inputs/Gangguan-stres-pascatrauma:0' shape=(None,) dtype=int32>, 'Skizofrenia': <tf.Tensor 'inputs/Skizofrenia:0' shape=(None,) dtype=int32>}. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'Age': <tf.Tensor 'inputs/Age:0' shape=(None,) dtype=int64>, 'Gender': <tf.Tensor 'inputs/Gender:0' shape=(None,) dtype=string>, 'ADHD-Hiperaktif-dan-kurang-fokus': <tf.Tensor 'inputs/ADHD-Hiperaktif-dan-kurang-fokus:0' shape=(None,) dtype=int32>, 'Depresi': <tf.Tensor 'inputs/Depresi:0' shape=(None,) dtype=int32>, 'Gangguan-kecemasan': <tf.Tensor 'inputs/Gangguan-kecemasan:0' shape=(None,) dtype=int32>, 'Gangguan-makan': <tf.Tensor 'inputs/Gangguan-makan:0' shape=(None,) dtype=int32>, 'Gangguan-stres-pascatrauma': <tf.Tensor 'inputs/Gangguan-stres-pascatrauma:0' shape=(None,) dtype=int32>, 'Skizofrenia': <tf.Tensor 'inputs/Skizofrenia:0' shape=(None,) dtype=int32>}. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) ADHD-Hiperaktif-dan-kurang-fokus, Age, Depresi, Gangguan-kecemasan, Gangguan-makan, Gangguan-stres-pascatrauma, Gender, Skizofrenia with unsupported characters which will be renamed to adhd_hiperaktif_dan_kurang_fokus, age, depresi, gangguan_kecemasan, gangguan_makan, gangguan_stres_pascatrauma, gender, skizofrenia in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/user_query_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/user_query_v1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'CAREGIVER_ID': <tf.Tensor 'CAREGIVER_ID:0' shape=(None, None) dtype=int64>, 'Caregiver_Gender': <tf.Tensor 'Caregiver_Gender:0' shape=(None, None) dtype=string>, 'Caregiver_Age': <tf.Tensor 'Caregiver_Age:0' shape=(None, None) dtype=int64>, 'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus': <tf.Tensor 'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus:0' shape=(None, None) dtype=int32>, 'Caregiver-Depresi': <tf.Tensor 'Caregiver-Depresi:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-kecemasan': <tf.Tensor 'Caregiver-Gangguan-kecemasan:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-makan': <tf.Tensor 'Caregiver-Gangguan-makan:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-stres-pascatrauma': <tf.Tensor 'Caregiver-Gangguan-stres-pascatrauma:0' shape=(None, None) dtype=int32>, 'Caregiver-Skizofrenia': <tf.Tensor 'Caregiver-Skizofrenia:0' shape=(None, None) dtype=int32>}. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'CAREGIVER_ID': <tf.Tensor 'CAREGIVER_ID:0' shape=(None, None) dtype=int64>, 'Caregiver_Gender': <tf.Tensor 'Caregiver_Gender:0' shape=(None, None) dtype=string>, 'Caregiver_Age': <tf.Tensor 'Caregiver_Age:0' shape=(None, None) dtype=int64>, 'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus': <tf.Tensor 'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus:0' shape=(None, None) dtype=int32>, 'Caregiver-Depresi': <tf.Tensor 'Caregiver-Depresi:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-kecemasan': <tf.Tensor 'Caregiver-Gangguan-kecemasan:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-makan': <tf.Tensor 'Caregiver-Gangguan-makan:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-stres-pascatrauma': <tf.Tensor 'Caregiver-Gangguan-stres-pascatrauma:0' shape=(None, None) dtype=int32>, 'Caregiver-Skizofrenia': <tf.Tensor 'Caregiver-Skizofrenia:0' shape=(None, None) dtype=int32>}. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'CAREGIVER_ID': <tf.Tensor 'inputs:0' shape=(None, None) dtype=int64>, 'Caregiver_Gender': <tf.Tensor 'inputs_8:0' shape=(None, None) dtype=string>, 'Caregiver_Age': <tf.Tensor 'inputs_7:0' shape=(None, None) dtype=int64>, 'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus': <tf.Tensor 'inputs_1:0' shape=(None, None) dtype=int32>, 'Caregiver-Depresi': <tf.Tensor 'inputs_2:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-kecemasan': <tf.Tensor 'inputs_3:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-makan': <tf.Tensor 'inputs_4:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-stres-pascatrauma': <tf.Tensor 'inputs_5:0' shape=(None, None) dtype=int32>, 'Caregiver-Skizofrenia': <tf.Tensor 'inputs_6:0' shape=(None, None) dtype=int32>}. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'CAREGIVER_ID': <tf.Tensor 'inputs:0' shape=(None, None) dtype=int64>, 'Caregiver_Gender': <tf.Tensor 'inputs_8:0' shape=(None, None) dtype=string>, 'Caregiver_Age': <tf.Tensor 'inputs_7:0' shape=(None, None) dtype=int64>, 'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus': <tf.Tensor 'inputs_1:0' shape=(None, None) dtype=int32>, 'Caregiver-Depresi': <tf.Tensor 'inputs_2:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-kecemasan': <tf.Tensor 'inputs_3:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-makan': <tf.Tensor 'inputs_4:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-stres-pascatrauma': <tf.Tensor 'inputs_5:0' shape=(None, None) dtype=int32>, 'Caregiver-Skizofrenia': <tf.Tensor 'inputs_6:0' shape=(None, None) dtype=int32>}. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'CAREGIVER_ID': <tf.Tensor 'inputs:0' shape=(None, None) dtype=int64>, 'Caregiver_Gender': <tf.Tensor 'inputs_8:0' shape=(None, None) dtype=string>, 'Caregiver_Age': <tf.Tensor 'inputs_7:0' shape=(None, None) dtype=int64>, 'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus': <tf.Tensor 'inputs_1:0' shape=(None, None) dtype=int32>, 'Caregiver-Depresi': <tf.Tensor 'inputs_2:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-kecemasan': <tf.Tensor 'inputs_3:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-makan': <tf.Tensor 'inputs_4:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-stres-pascatrauma': <tf.Tensor 'inputs_5:0' shape=(None, None) dtype=int32>, 'Caregiver-Skizofrenia': <tf.Tensor 'inputs_6:0' shape=(None, None) dtype=int32>}. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'CAREGIVER_ID': <tf.Tensor 'inputs:0' shape=(None, None) dtype=int64>, 'Caregiver_Gender': <tf.Tensor 'inputs_8:0' shape=(None, None) dtype=string>, 'Caregiver_Age': <tf.Tensor 'inputs_7:0' shape=(None, None) dtype=int64>, 'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus': <tf.Tensor 'inputs_1:0' shape=(None, None) dtype=int32>, 'Caregiver-Depresi': <tf.Tensor 'inputs_2:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-kecemasan': <tf.Tensor 'inputs_3:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-makan': <tf.Tensor 'inputs_4:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-stres-pascatrauma': <tf.Tensor 'inputs_5:0' shape=(None, None) dtype=int32>, 'Caregiver-Skizofrenia': <tf.Tensor 'inputs_6:0' shape=(None, None) dtype=int32>}. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'CAREGIVER_ID': <tf.Tensor 'CAREGIVER_ID:0' shape=(None, None) dtype=int64>, 'Caregiver_Gender': <tf.Tensor 'Caregiver_Gender:0' shape=(None, None) dtype=string>, 'Caregiver_Age': <tf.Tensor 'Caregiver_Age:0' shape=(None, None) dtype=int64>, 'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus': <tf.Tensor 'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus:0' shape=(None, None) dtype=int32>, 'Caregiver-Depresi': <tf.Tensor 'Caregiver-Depresi:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-kecemasan': <tf.Tensor 'Caregiver-Gangguan-kecemasan:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-makan': <tf.Tensor 'Caregiver-Gangguan-makan:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-stres-pascatrauma': <tf.Tensor 'Caregiver-Gangguan-stres-pascatrauma:0' shape=(None, None) dtype=int32>, 'Caregiver-Skizofrenia': <tf.Tensor 'Caregiver-Skizofrenia:0' shape=(None, None) dtype=int32>}. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'CAREGIVER_ID': <tf.Tensor 'CAREGIVER_ID:0' shape=(None, None) dtype=int64>, 'Caregiver_Gender': <tf.Tensor 'Caregiver_Gender:0' shape=(None, None) dtype=string>, 'Caregiver_Age': <tf.Tensor 'Caregiver_Age:0' shape=(None, None) dtype=int64>, 'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus': <tf.Tensor 'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus:0' shape=(None, None) dtype=int32>, 'Caregiver-Depresi': <tf.Tensor 'Caregiver-Depresi:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-kecemasan': <tf.Tensor 'Caregiver-Gangguan-kecemasan:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-makan': <tf.Tensor 'Caregiver-Gangguan-makan:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-stres-pascatrauma': <tf.Tensor 'Caregiver-Gangguan-stres-pascatrauma:0' shape=(None, None) dtype=int32>, 'Caregiver-Skizofrenia': <tf.Tensor 'Caregiver-Skizofrenia:0' shape=(None, None) dtype=int32>}. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'CAREGIVER_ID': <tf.Tensor 'CAREGIVER_ID:0' shape=(None, None) dtype=int64>, 'Caregiver_Gender': <tf.Tensor 'Caregiver_Gender:0' shape=(None, None) dtype=string>, 'Caregiver_Age': <tf.Tensor 'Caregiver_Age:0' shape=(None, None) dtype=int64>, 'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus': <tf.Tensor 'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus:0' shape=(None, None) dtype=int32>, 'Caregiver-Depresi': <tf.Tensor 'Caregiver-Depresi:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-kecemasan': <tf.Tensor 'Caregiver-Gangguan-kecemasan:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-makan': <tf.Tensor 'Caregiver-Gangguan-makan:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-stres-pascatrauma': <tf.Tensor 'Caregiver-Gangguan-stres-pascatrauma:0' shape=(None, None) dtype=int32>, 'Caregiver-Skizofrenia': <tf.Tensor 'Caregiver-Skizofrenia:0' shape=(None, None) dtype=int32>}. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'CAREGIVER_ID': <tf.Tensor 'CAREGIVER_ID:0' shape=(None, None) dtype=int64>, 'Caregiver_Gender': <tf.Tensor 'Caregiver_Gender:0' shape=(None, None) dtype=string>, 'Caregiver_Age': <tf.Tensor 'Caregiver_Age:0' shape=(None, None) dtype=int64>, 'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus': <tf.Tensor 'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus:0' shape=(None, None) dtype=int32>, 'Caregiver-Depresi': <tf.Tensor 'Caregiver-Depresi:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-kecemasan': <tf.Tensor 'Caregiver-Gangguan-kecemasan:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-makan': <tf.Tensor 'Caregiver-Gangguan-makan:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-stres-pascatrauma': <tf.Tensor 'Caregiver-Gangguan-stres-pascatrauma:0' shape=(None, None) dtype=int32>, 'Caregiver-Skizofrenia': <tf.Tensor 'Caregiver-Skizofrenia:0' shape=(None, None) dtype=int32>}. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'CAREGIVER_ID': <tf.Tensor 'inputs/CAREGIVER_ID:0' shape=(None, None) dtype=int64>, 'Caregiver_Gender': <tf.Tensor 'inputs/Caregiver_Gender:0' shape=(None, None) dtype=string>, 'Caregiver_Age': <tf.Tensor 'inputs/Caregiver_Age:0' shape=(None, None) dtype=int64>, 'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus': <tf.Tensor 'inputs/Caregiver-ADHD-Hiperaktif-dan-kurang-fokus:0' shape=(None, None) dtype=int32>, 'Caregiver-Depresi': <tf.Tensor 'inputs/Caregiver-Depresi:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-kecemasan': <tf.Tensor 'inputs/Caregiver-Gangguan-kecemasan:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-makan': <tf.Tensor 'inputs/Caregiver-Gangguan-makan:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-stres-pascatrauma': <tf.Tensor 'inputs/Caregiver-Gangguan-stres-pascatrauma:0' shape=(None, None) dtype=int32>, 'Caregiver-Skizofrenia': <tf.Tensor 'inputs/Caregiver-Skizofrenia:0' shape=(None, None) dtype=int32>}. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'CAREGIVER_ID': <tf.Tensor 'inputs/CAREGIVER_ID:0' shape=(None, None) dtype=int64>, 'Caregiver_Gender': <tf.Tensor 'inputs/Caregiver_Gender:0' shape=(None, None) dtype=string>, 'Caregiver_Age': <tf.Tensor 'inputs/Caregiver_Age:0' shape=(None, None) dtype=int64>, 'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus': <tf.Tensor 'inputs/Caregiver-ADHD-Hiperaktif-dan-kurang-fokus:0' shape=(None, None) dtype=int32>, 'Caregiver-Depresi': <tf.Tensor 'inputs/Caregiver-Depresi:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-kecemasan': <tf.Tensor 'inputs/Caregiver-Gangguan-kecemasan:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-makan': <tf.Tensor 'inputs/Caregiver-Gangguan-makan:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-stres-pascatrauma': <tf.Tensor 'inputs/Caregiver-Gangguan-stres-pascatrauma:0' shape=(None, None) dtype=int32>, 'Caregiver-Skizofrenia': <tf.Tensor 'inputs/Caregiver-Skizofrenia:0' shape=(None, None) dtype=int32>}. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'CAREGIVER_ID': <tf.Tensor 'inputs/CAREGIVER_ID:0' shape=(None, None) dtype=int64>, 'Caregiver_Gender': <tf.Tensor 'inputs/Caregiver_Gender:0' shape=(None, None) dtype=string>, 'Caregiver_Age': <tf.Tensor 'inputs/Caregiver_Age:0' shape=(None, None) dtype=int64>, 'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus': <tf.Tensor 'inputs/Caregiver-ADHD-Hiperaktif-dan-kurang-fokus:0' shape=(None, None) dtype=int32>, 'Caregiver-Depresi': <tf.Tensor 'inputs/Caregiver-Depresi:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-kecemasan': <tf.Tensor 'inputs/Caregiver-Gangguan-kecemasan:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-makan': <tf.Tensor 'inputs/Caregiver-Gangguan-makan:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-stres-pascatrauma': <tf.Tensor 'inputs/Caregiver-Gangguan-stres-pascatrauma:0' shape=(None, None) dtype=int32>, 'Caregiver-Skizofrenia': <tf.Tensor 'inputs/Caregiver-Skizofrenia:0' shape=(None, None) dtype=int32>}. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'CAREGIVER_ID': <tf.Tensor 'inputs/CAREGIVER_ID:0' shape=(None, None) dtype=int64>, 'Caregiver_Gender': <tf.Tensor 'inputs/Caregiver_Gender:0' shape=(None, None) dtype=string>, 'Caregiver_Age': <tf.Tensor 'inputs/Caregiver_Age:0' shape=(None, None) dtype=int64>, 'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus': <tf.Tensor 'inputs/Caregiver-ADHD-Hiperaktif-dan-kurang-fokus:0' shape=(None, None) dtype=int32>, 'Caregiver-Depresi': <tf.Tensor 'inputs/Caregiver-Depresi:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-kecemasan': <tf.Tensor 'inputs/Caregiver-Gangguan-kecemasan:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-makan': <tf.Tensor 'inputs/Caregiver-Gangguan-makan:0' shape=(None, None) dtype=int32>, 'Caregiver-Gangguan-stres-pascatrauma': <tf.Tensor 'inputs/Caregiver-Gangguan-stres-pascatrauma:0' shape=(None, None) dtype=int32>, 'Caregiver-Skizofrenia': <tf.Tensor 'inputs/Caregiver-Skizofrenia:0' shape=(None, None) dtype=int32>}. Consider rewriting this model with the Functional API.\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) CAREGIVER_ID, Caregiver-ADHD-Hiperaktif-dan-kurang-fokus, Caregiver-Depresi, Caregiver-Gangguan-kecemasan, Caregiver-Gangguan-makan, Caregiver-Gangguan-stres-pascatrauma, Caregiver-Skizofrenia, Caregiver_Age, Caregiver_Gender with unsupported characters which will be renamed to caregiver_id, caregiver_adhd_hiperaktif_dan_kurang_fokus, caregiver_depresi, caregiver_gangguan_kecemasan, caregiver_gangguan_makan, caregiver_gangguan_stres_pascatrauma, caregiver_skizofrenia, caregiver_age, caregiver_gender in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/caregiver_query_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/caregiver_query_v1\\assets\n"
     ]
    }
   ],
   "source": [
    "model.user_model.save('saved_model/user_query_v1')\n",
    "model.caregiver_model.save('saved_model/caregiver_query_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "86eba516",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MAIN_USER_MODEL =  tf.saved_model.load('saved_model/user_query_v1')\n",
    "MAIN_CAREGIVER_MODEL = tf.saved_model.load('saved_model/caregiver_query_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d326d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_test = caregiver_ds.map(lambda features: (features['CAREGIVER_ID'], MAIN_CAREGIVER_MODEL(features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18a9d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_USER_MODEL(dictionary_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7a6091",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_CAREGIVER_MODEL(dictionary_Test_Caregiver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067f22b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0a827c5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: saved_model_v1/user_query_v1/saved_model.pb\\{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Convert the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m converter \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFLiteConverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_saved_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msaved_model_v1/user_query_v1/saved_model.pb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# path to the SavedModel directory\u001b[39;00m\n\u001b[0;32m      3\u001b[0m tflite_model \u001b[38;5;241m=\u001b[39m converter\u001b[38;5;241m.\u001b[39mconvert()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Save the model.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\asus\\anaconda3\\envs\\notebook\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py:1648\u001b[0m, in \u001b[0;36mTFLiteConverterV2.from_saved_model\u001b[1;34m(cls, saved_model_dir, signature_keys, tags)\u001b[0m\n\u001b[0;32m   1645\u001b[0m   tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m([_tag_constants\u001b[38;5;241m.\u001b[39mSERVING])\n\u001b[0;32m   1647\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39meager_mode():\n\u001b[1;32m-> 1648\u001b[0m   saved_model \u001b[38;5;241m=\u001b[39m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43msaved_model_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signature_keys:\n\u001b[0;32m   1650\u001b[0m   signature_keys \u001b[38;5;241m=\u001b[39m saved_model\u001b[38;5;241m.\u001b[39msignatures\n",
      "File \u001b[1;32mc:\\users\\asus\\anaconda3\\envs\\notebook\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:936\u001b[0m, in \u001b[0;36mload\u001b[1;34m(export_dir, tags, options)\u001b[0m\n\u001b[0;32m    845\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaved_model.load\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaved_model.load_v2\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    846\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(export_dir, tags\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    847\u001b[0m   \u001b[38;5;124;03m\"\"\"Load a SavedModel from `export_dir`.\u001b[39;00m\n\u001b[0;32m    848\u001b[0m \n\u001b[0;32m    849\u001b[0m \u001b[38;5;124;03m  Signatures associated with the SavedModel are available as functions:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;124;03m    ValueError: If `tags` don't match a MetaGraph in the SavedModel.\u001b[39;00m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 936\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mload_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    937\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\users\\asus\\anaconda3\\envs\\notebook\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:949\u001b[0m, in \u001b[0;36mload_internal\u001b[1;34m(export_dir, tags, options, loader_cls, filters)\u001b[0m\n\u001b[0;32m    944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tags \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tags, \u001b[38;5;28mset\u001b[39m):\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# Supports e.g. tags=SERVING and tags=[SERVING]. Sets aren't considered\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# sequences for nest.flatten, so we put those through as-is.\u001b[39;00m\n\u001b[0;32m    947\u001b[0m   tags \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mflatten(tags)\n\u001b[0;32m    948\u001b[0m saved_model_proto, debug_info \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 949\u001b[0m     \u001b[43mloader_impl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_saved_model_with_debug_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(saved_model_proto\u001b[38;5;241m.\u001b[39mmeta_graphs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    952\u001b[0m     saved_model_proto\u001b[38;5;241m.\u001b[39mmeta_graphs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mHasField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject_graph_def\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m    953\u001b[0m   metrics\u001b[38;5;241m.\u001b[39mIncrementReadApi(_LOAD_V2_LABEL)\n",
      "File \u001b[1;32mc:\\users\\asus\\anaconda3\\envs\\notebook\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py:57\u001b[0m, in \u001b[0;36mparse_saved_model_with_debug_info\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_saved_model_with_debug_info\u001b[39m(export_dir):\n\u001b[0;32m     45\u001b[0m   \u001b[38;5;124;03m\"\"\"Reads the savedmodel as well as the graph debug info.\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;124;03m    parsed. Missing graph debug info file is fine.\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m   saved_model \u001b[38;5;241m=\u001b[39m \u001b[43mparse_saved_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m   debug_info_path \u001b[38;5;241m=\u001b[39m file_io\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m     60\u001b[0m       saved_model_utils\u001b[38;5;241m.\u001b[39mget_debug_dir(export_dir),\n\u001b[0;32m     61\u001b[0m       constants\u001b[38;5;241m.\u001b[39mDEBUG_INFO_FILENAME_PB)\n\u001b[0;32m     62\u001b[0m   debug_info \u001b[38;5;241m=\u001b[39m graph_debug_info_pb2\u001b[38;5;241m.\u001b[39mGraphDebugInfo()\n",
      "File \u001b[1;32mc:\\users\\asus\\anaconda3\\envs\\notebook\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py:115\u001b[0m, in \u001b[0;36mparse_saved_model\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot parse file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_to_pbtxt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 115\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[0;32m    116\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSavedModel file does not exist at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexport_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    117\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mconstants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_FILENAME_PBTXT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    118\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_FILENAME_PB\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: SavedModel file does not exist at: saved_model_v1/user_query_v1/saved_model.pb\\{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model('saved_model_v1/user_query_v1/saved_model.pb') # path to the SavedModel directory\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('saved_model_tflite_v1/text_query_v1', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb682b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac232cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a206cb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
